{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script src=\"https://spcl.github.io/dace-webclient/dist/sdfv.js\"></script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dace\n",
    "import typing\n",
    "import os\n",
    "import numpy as np\n",
    "import ast\n",
    "from dace.transformation.dataflow import DoubleBuffering, MapTiling\n",
    "from dace.transformation.soft_hier import SystolocTransformer, SystolicTransformer, SystolicSplitStore, SummaTransformer, BSPTransformer, TESTBSPTransformer, SplitKReduction\n",
    "from dace.soft_hier import generate_arg_cfg, make_preload_elf, make_preload_elf_hbm_interleaved_new, InterleaveHandler\n",
    "from dace.soft_hier import generate_systolic_BSP, generate_cannon_BSP, generate_summa_BSP, generate_summa_systolic_BSP, generate_split_K_summa_systolic_BSP\n",
    "from dace.properties import CodeBlock\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _my_gen_matmul_sdfg(hardware_matmul_mnk: typing.Tuple,\n",
    "                     global_storage: dace.dtypes.StorageType,\n",
    "                     local_storage: dace.dtypes.StorageType,\n",
    "                     device_schedule: dace.dtypes.ScheduleType,\n",
    "                     thread_group_schedule: dace.dtypes.ScheduleType,\n",
    "                     thread_group_dims: typing.Tuple,\n",
    "                     k_group_dims: typing.Tuple,\n",
    "                     hbm_split_scheme: typing.List[typing.Tuple[int, int]],\n",
    "                     hbm_placement_scheme: typing.List[typing.Tuple[int, int]],\n",
    "                     input_float,\n",
    "                     output_float,\n",
    "                     mmad_tasklet_str: str,\n",
    "                     coarsening_factor=1,\n",
    "                     is_hbm_interleaved: bool = False):\n",
    "    sdfg = dace.SDFG(\"GEMM\")\n",
    "    tM, tN, tK = hardware_matmul_mnk\n",
    "    tM *= coarsening_factor\n",
    "    tN *= coarsening_factor\n",
    "    tK *= coarsening_factor\n",
    "    gM, gN = thread_group_dims\n",
    "\n",
    "    kg_m, kg_n = k_group_dims\n",
    "\n",
    "    main_state = sdfg.add_state(\"main\")\n",
    "    state = main_state\n",
    "\n",
    "    arrs = dict()\n",
    "    for arr_name, shape, ftype in [(\"A\", (M, K), input_float), (\"B\", (K, N), input_float), (\"C\", (M, N), output_float)]:\n",
    "        if arr_name == \"A\":\n",
    "            arrn, arr = sdfg.add_array(name=arr_name, shape=shape, dtype=ftype, storage=global_storage, transient=False, is_hbm_interleaved=is_hbm_interleaved, hbm_split_scheme=hbm_split_scheme[0], hbm_placement_scheme=hbm_placement_scheme[0])\n",
    "            arrs[arrn] = arr\n",
    "        if arr_name == \"B\":\n",
    "            arrn, arr = sdfg.add_array(name=arr_name, shape=shape, dtype=ftype, storage=global_storage, transient=False, is_hbm_interleaved=is_hbm_interleaved, hbm_split_scheme=hbm_split_scheme[1], hbm_placement_scheme=hbm_placement_scheme[1])\n",
    "            arrs[arrn] = arr\n",
    "        if arr_name == \"C\":\n",
    "            arrn, arr = sdfg.add_array(name=arr_name, shape=shape, dtype=ftype, storage=global_storage, transient=False, is_hbm_interleaved=is_hbm_interleaved, hbm_split_scheme=hbm_split_scheme[2], hbm_placement_scheme=hbm_placement_scheme[2])\n",
    "            arrs[arrn] = arr\n",
    "    arrn, arr = sdfg.add_array(name=\"accumulator\", shape=(coarsening_factor*coarsening_factor, tM//coarsening_factor, tN//coarsening_factor), dtype=ftype, storage=local_storage, transient=True)\n",
    "    arrs[arrn] = arr\n",
    "\n",
    "    dev_map_entry, dev_map_exit = main_state.add_map(\n",
    "        name=\"gemm_entry\",\n",
    "        ndrange={\"i\" : dace.subsets.Range([(0, M-1, tM*gM//kg_m)]),\n",
    "                 \"j\" : dace.subsets.Range([(0, N-1, tN*gN//kg_n)])},\n",
    "        schedule=device_schedule\n",
    "    )\n",
    "    i = dace.symbol(\"i\")\n",
    "    j = dace.symbol(\"j\")\n",
    "\n",
    "    for name in [\"A\", \"B\", \"C\"]:\n",
    "    # for name in [\"A\", \"B\"]:\n",
    "        if name == \"A\" or name == \"B\":\n",
    "            access_str = \", \".join([f\"0:{n}\" for n in arrs[name].shape])\n",
    "            an = state.add_access(name)\n",
    "            state.add_edge(an, None, dev_map_entry, f\"IN_{name}\", dace.memlet.Memlet(f\"{name}[{access_str}]\"))\n",
    "            dev_map_entry.add_in_connector(f\"IN_{name}\")\n",
    "        if name == \"C\":\n",
    "            access_str = \", \".join([f\"0:{n}\" for n in arrs[name].shape])\n",
    "            dev_map_exit.add_out_connector(f\"OUT_{name}\")\n",
    "            anc3 = state.add_access(name)\n",
    "            state.add_edge(dev_map_exit, f\"OUT_{name}\", anc3, None, dace.memlet.Memlet(f\"{name}[{access_str}]\"))\n",
    "\n",
    "    thread_group_map_entry, thread_group_map_exit = main_state.add_map(\n",
    "        name=\"thread_group_mmad\",\n",
    "        ndrange={\"gi\" : dace.subsets.Range([(0, gM-1, 1)]),\n",
    "                 \"gj\" : dace.subsets.Range([(0, gN-1, 1)])},\n",
    "        schedule=thread_group_schedule\n",
    "    )\n",
    "\n",
    "    gi = dace.symbol(\"gi\")\n",
    "    gj = dace.symbol(\"gj\")\n",
    "    kg_i = gi // kg_m\n",
    "    kg_j = gj // kg_n\n",
    "    kg_oi = gi % kg_m\n",
    "    kg_oj = gj % kg_n\n",
    "    kg_num = kg_m * kg_n\n",
    "    kg_off = kg_oi * kg_n + kg_oj\n",
    "    bK_start = kg_off * (K // kg_num)\n",
    "    bK_end = (kg_off + 1) * (K // kg_num)\n",
    "\n",
    "    for name in [\"A\", \"B\", \"C\"]:\n",
    "        if name == \"A\" or name == \"B\":\n",
    "            if name == \"A\":\n",
    "                access_str = \", \".join([f\"i:i + {tM} * {gM} / {kg_m}\", \"0:K\"])\n",
    "            elif name == \"B\":\n",
    "                access_str = \", \".join([\"0:K\", f\"j:j + {tN} * {gN} / {kg_n}\"])\n",
    "            elif name == \"C\":\n",
    "                access_str = \", \".join([f\"i:i + {gM} * {tM} / {kg_m}\", f\"j:j + {gN} * {tN} / {kg_n}\"])\n",
    "            state.add_edge(dev_map_entry, f\"OUT_{name}\", thread_group_map_entry, f\"IN_{name}\", dace.memlet.Memlet(f\"{name}[{access_str}]\"))\n",
    "            dev_map_entry.add_out_connector(f\"OUT_{name}\")\n",
    "            thread_group_map_entry.add_in_connector(f\"IN_{name}\")\n",
    "        if name == \"C\":\n",
    "            access_str = \", \".join([f\"i:i + {gM} * {tM} / {kg_m}\", f\"j:j + {gN} * {tN} / {kg_n}\"])\n",
    "            state.add_edge(thread_group_map_exit, f\"OUT_{name}\", dev_map_exit, f\"IN_{name}\", dace.memlet.Memlet(f\"{name}[{access_str}]\"))\n",
    "            dev_map_exit.add_in_connector(f\"IN_{name}\")\n",
    "            thread_group_map_exit.add_out_connector(f\"OUT_{name}\")\n",
    "\n",
    "    thread_coarsened_map_entry, thread_coarsened_map_exit = main_state.add_map(\n",
    "        name=\"thread_coarsened\",\n",
    "        ndrange={\"ci\" : dace.subsets.Range([(0, tM-1, tM//coarsening_factor)]),\n",
    "                 \"cj\" : dace.subsets.Range([(0, tN-1, tN//coarsening_factor)])},\n",
    "        schedule=dace.dtypes.ScheduleType.SoftHier_Sequential\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "    for name in [\"A\", \"B\", \"C\"]:\n",
    "        if name == \"A\" or name == \"B\":\n",
    "                if name == \"A\":\n",
    "                    access_str = \", \".join([f\"i + {kg_i} * {tM}:i + {kg_i} * {tM} + {tM}\", \"0:K\"])\n",
    "                    access_subsets = dace.subsets.Range([(f\"i + {kg_i} * {tM}\",f\"i + {kg_i} * {tM} + {tM} - 1\",1), \n",
    "                                                         (0,K-1,1)])\n",
    "                elif name == \"B\":\n",
    "                    access_str = \", \".join([\"0:K\", f\"j + {kg_j} * {tN}:j + {kg_j} * {tN} + {tN}\"])\n",
    "                    access_subsets = dace.subsets.Range([(0,K-1,1), \n",
    "                                                         (f\"j + {kg_j} * {tN}\",f\"j + {kg_j} * {tN} + {tN} - 1\",1)])\n",
    "                state.add_edge(thread_group_map_entry, f\"OUT_{name}\", thread_coarsened_map_entry, f\"IN_{name}\", \n",
    "                               dace.memlet.Memlet(\n",
    "                                    data=f\"{name}\",\n",
    "                                    subset=access_subsets\n",
    "                               ))\n",
    "                thread_group_map_entry.add_out_connector(f\"OUT_{name}\")\n",
    "                thread_coarsened_map_entry.add_in_connector(f\"IN_{name}\")\n",
    "        if name == \"C\":\n",
    "            access_str = \", \".join([f\"i + {kg_i} * {tM}:i + {kg_i} * {tM} + {tM}\", f\"j + {kg_j} * {tN}:j + {kg_j} * {tN} + {tN}\"])\n",
    "            access_subsets = dace.subsets.Range([(f\"i + {kg_i} * {tM}\",f\"i + {kg_i} * {tM} + {tM} - 1\",1), \n",
    "                                                 (f\"j + {kg_j} * {tN}\",f\"j + {kg_j} * {tN} + {tN} - 1\",1)])\n",
    "            # state.add_edge(thread_coarsened_map_exit, f\"OUT_{name}\", thread_group_map_exit, f\"IN_{name}\", dace.memlet.Memlet(f\"{name}[{access_str}]\"))\n",
    "            state.add_edge(thread_coarsened_map_exit, f\"OUT_{name}\", thread_group_map_exit, f\"IN_{name}\",\n",
    "                           dace.memlet.Memlet(\n",
    "                                data=f\"{name}\",\n",
    "                                subset=access_subsets\n",
    "                           ))\n",
    "            thread_group_map_exit.add_in_connector(f\"IN_{name}\")\n",
    "            thread_coarsened_map_exit.add_out_connector(f\"OUT_{name}\")\n",
    "\n",
    "    \n",
    "\n",
    "    block_tiled_map_entry, block_tiled_map_exit = main_state.add_map(\n",
    "        name=\"block_tiled\",\n",
    "        # ndrange={\"bK\" : dace.subsets.Range([(0, K-1, tK//coarsening_factor)])},\n",
    "        ndrange={\"bK\" : dace.subsets.Range([(bK_start, bK_end-1, tK//coarsening_factor)])},\n",
    "        schedule=dace.dtypes.ScheduleType.SoftHier_Sequential\n",
    "    )\n",
    "\n",
    "    accumulator_an = state.add_access(\"accumulator\")\n",
    "    accumulator_an.setzero = True\n",
    "    state.add_edge(thread_coarsened_map_entry, None, accumulator_an, None, dace.memlet.Memlet(None))\n",
    "    access_str = \", \".join([f\"0:{coarsening_factor}*{coarsening_factor}\", f\"0:{tM//coarsening_factor}\", f\"0:{tN//coarsening_factor}\"])\n",
    "    state.add_edge(accumulator_an, None, block_tiled_map_entry, f\"IN_accumulator\", dace.memlet.Memlet(f\"accumulator[{access_str}]\"))\n",
    "    block_tiled_map_entry.add_in_connector(\"IN_accumulator\")\n",
    "    thread_group_map_entry\n",
    "\n",
    "\n",
    "    for name in [\"A\", \"B\"]:\n",
    "        if name == \"A\":\n",
    "            access_str = \", \".join([f\"i + {kg_i} * {tM} + ci * {tM//coarsening_factor}:i + {kg_i} * {tM} + ci * {tM//coarsening_factor} + {tM//coarsening_factor}\", \"0:K\"])\n",
    "            access_subsets = dace.subsets.Range([(f\"i + {kg_i} * {tM} + ci * {tM//coarsening_factor}\",\n",
    "                                                  f\"i + {kg_i} * {tM} + ci * {tM//coarsening_factor} + {tM//coarsening_factor} - 1\",\n",
    "                                                  1), \n",
    "                                                 (0,K-1,1)])\n",
    "        elif name == \"B\":\n",
    "            access_str = \", \".join([\"0:K\", f\"j + {kg_j} * {tN} + cj * {tN//coarsening_factor}:j + {kg_j} * {tN} + cj * {tN//coarsening_factor} + {tN//coarsening_factor}\"])\n",
    "            access_subsets = dace.subsets.Range([(0,K-1,1), \n",
    "                                                 (f\"j + {kg_j} * {tN} + cj * {tN//coarsening_factor}\",\n",
    "                                                  f\"j + {kg_j} * {tN} + cj * {tN//coarsening_factor} + {tN//coarsening_factor} - 1\",\n",
    "                                                  1)])\n",
    "\n",
    "        # state.add_edge(thread_coarsened_map_entry, f\"OUT_{name}\", block_tiled_map_entry, f\"IN_{name}\", dace.memlet.Memlet(f\"{name}[{access_str}]\"))\n",
    "        state.add_edge(thread_coarsened_map_entry, f\"OUT_{name}\", block_tiled_map_entry, f\"IN_{name}\",\n",
    "                       dace.memlet.Memlet(\n",
    "                            data=f\"{name}\",\n",
    "                            subset=access_subsets\n",
    "                       ))\n",
    "        block_tiled_map_entry.add_in_connector(f\"IN_{name}\")\n",
    "        thread_coarsened_map_entry.add_out_connector(f\"OUT_{name}\")\n",
    "\n",
    "\n",
    "    # Load\n",
    "    local_access_nodes = dict()\n",
    "    for name, shape in [(\"A\", (tM//coarsening_factor, tK//coarsening_factor)), (\"B\", (tK//coarsening_factor, tN//coarsening_factor))]:\n",
    "        block_tiled_map_entry.add_out_connector(f\"OUT_{name}\")\n",
    "        arrn, arr = sdfg.add_array(name=f\"local_{name}\", shape=shape, dtype=input_float, storage=local_storage, transient=True)\n",
    "        arrs[arrn] = arr\n",
    "        an = state.add_access(f\"local_{name}\")\n",
    "        local_access_nodes[f\"local_{name}\"] = an\n",
    "        if name == \"A\":\n",
    "            access_str = \", \".join([f\"i + {kg_i} * {tM} + ci * {tM//coarsening_factor}:i + {kg_i} * {tM} + ci * {tM//coarsening_factor} + {tM//coarsening_factor}\", \n",
    "                                    f\"bK:bK+{tK//coarsening_factor}\"])\n",
    "            access_subsets = dace.subsets.Range([(f\"i + {kg_i} * {tM} + ci * {tM//coarsening_factor}\",\n",
    "                                                  f\"i + {kg_i} * {tM} + ci * {tM//coarsening_factor} + {tM//coarsening_factor}-1\",\n",
    "                                                  1), \n",
    "                                                 (f\"bK\",\n",
    "                                                  f\"bK+{tK//coarsening_factor}-1\",\n",
    "                                                  1)])\n",
    "        elif name == \"B\":\n",
    "            access_str = \", \".join([f\"bK:bK+{tK//coarsening_factor}\", \n",
    "                                    f\"j + {kg_j} * {tN} + cj * {tN//coarsening_factor}:j + {kg_j} * {tN} + cj * {tN//coarsening_factor} + {tN//coarsening_factor}\"])\n",
    "            access_subsets = dace.subsets.Range([(f\"bK\",\n",
    "                                                  f\"bK+{tK//coarsening_factor}-1\",\n",
    "                                                  1), \n",
    "                                                 (f\"j + {kg_j} * {tN} + cj * {tN//coarsening_factor}\",\n",
    "                                                  f\"j + {kg_j} * {tN} + cj * {tN//coarsening_factor} + {tN//coarsening_factor}-1\",\n",
    "                                                  1)])\n",
    "        # state.add_edge(block_tiled_map_entry, f\"OUT_{name}\", an, None, dace.memlet.Memlet(f\"{name}[{access_str}]\"))\n",
    "        state.add_edge(block_tiled_map_entry, f\"OUT_{name}\", an, None,\n",
    "                       dace.memlet.Memlet(\n",
    "                            data=f\"{name}\",\n",
    "                            subset=access_subsets\n",
    "                       ))\n",
    "\n",
    "    # Connect local_A + local_B -> matmul -> accumulator\n",
    "    matmul_tasklet = state.add_tasklet(name=\"mmad_redmule\", inputs={\"_in_local_a\", \"_in_local_b\", \"_in_accumulator\"}, outputs={\"_out_accumulator\"},\n",
    "                                       code=mmad_tasklet_str, language=dace.dtypes.Language.CPP)\n",
    "\n",
    "\n",
    "\n",
    "    for name, an in local_access_nodes.items():\n",
    "        state.add_edge(an, None, matmul_tasklet, \"_in_\" + name.lower(), dace.memlet.Memlet(name))\n",
    "    state.add_edge(block_tiled_map_entry, f\"OUT_accumulator\", matmul_tasklet, \"_in_accumulator\", dace.memlet.Memlet(\"accumulator\"))\n",
    "    access_str = \", \".join([f\"0:{coarsening_factor}*{coarsening_factor}\", f\"0:{tM//coarsening_factor}\", f\"0:{tN//coarsening_factor}\"])\n",
    "    state.add_edge(matmul_tasklet, \"_out_accumulator\", block_tiled_map_exit, \"IN_accumulator\", dace.memlet.Memlet(f\"accumulator[{access_str}]\"))\n",
    "    block_tiled_map_entry.add_in_connector(\"IN_accumulator\")\n",
    "    block_tiled_map_exit.add_in_connector(\"IN_accumulator\")\n",
    "    block_tiled_map_entry.add_out_connector(\"OUT_accumulator\")\n",
    "    block_tiled_map_exit.add_out_connector(\"OUT_accumulator\")\n",
    "\n",
    "\n",
    "    accumulator_an3 = state.add_access(\"accumulator\")\n",
    "    \n",
    "    access_str = \", \".join([f\"0:{coarsening_factor}*{coarsening_factor}\", f\"0:{tM//coarsening_factor}\", f\"0:{tN//coarsening_factor}\"])\n",
    "    state.add_edge(block_tiled_map_exit, f\"OUT_accumulator\", accumulator_an3, None, dace.memlet.Memlet(f\"accumulator[{access_str}]\"))\n",
    "    access_str = \", \".join([f\"i + {kg_i} * {tM} + ci * {tM//coarsening_factor}:i + {kg_i} * {tM} + ci * {tM//coarsening_factor} + {tM//coarsening_factor}\", \n",
    "                            f\"j + {kg_j} * {tN} + cj * {tN//coarsening_factor}:j + {kg_j} * {tN} + cj * {tN//coarsening_factor} + {tN//coarsening_factor}\"])\n",
    "    access_subsets = dace.subsets.Range([(f\"i + {kg_i} * {tM} + ci * {tM//coarsening_factor}\",\n",
    "                                          f\"i + {kg_i} * {tM} + ci * {tM//coarsening_factor} + {tM//coarsening_factor}-1\",\n",
    "                                          1), \n",
    "                                         (f\"j + {kg_j} * {tN} + cj * {tN//coarsening_factor}\",\n",
    "                                          f\"j + {kg_j} * {tN} + cj * {tN//coarsening_factor} + {tN//coarsening_factor}-1\",\n",
    "                                          1)])\n",
    "    # state.add_edge(accumulator_an3, None, thread_coarsened_map_exit, \"IN_C\", dace.memlet.Memlet(f\"C[{access_str}]\"))\n",
    "    state.add_edge(accumulator_an3, None, thread_coarsened_map_exit, \"IN_C\",\n",
    "                   dace.memlet.Memlet(\n",
    "                        data=\"C\",\n",
    "                        subset=access_subsets,\n",
    "                        wcr=\"lambda a, b: a + b\"\n",
    "                   ))\n",
    "    thread_coarsened_map_exit.add_in_connector(\"IN_C\")\n",
    "    SplitKReduction.apply_to(sdfg, accumulator=accumulator_an3, global_hbm=anc3,\n",
    "                             options={\"npe_x\": gM, \"npe_y\": gN, \n",
    "                                     \"gi\": gi, \"gj\": gj,\n",
    "                                    \"i\": i, \"j\": j,\n",
    "                                    \"M\": M, \"N\": N, \"K\": K,\n",
    "                                    \"tM\": tM, \"tN\": tN, \"tK\": tK,\n",
    "                                    \"kg_m\": kg_m, \"kg_n\": kg_n})\n",
    "    # return sdfg\n",
    "\n",
    "    (pre_shift_code_block, \n",
    "    BSP_stride,\n",
    "    BSP_init_code_block, \n",
    "    BSP_loop_code_block, \n",
    "    BSP_compute_code_block, \n",
    "    BSP_communication_code_block, \n",
    "    BSP_sync, \n",
    "    post_shift_code_block) = generate_split_K_summa_systolic_BSP(i, j, gi, gj, gM, gN, tM, tN, tK, M, N, K, k_group_dims=k_group_dims, summa_range=(1,8))\n",
    "\n",
    "    BSPTransformer.apply_to(sdfg, accumulator=accumulator_an, map_entry=block_tiled_map_entry, transient=local_access_nodes[\"local_A\"], \n",
    "                            options={\"npe_x\": gM, \"npe_y\": gN, \n",
    "                                     \"gi\": gi, \"gj\": gj,\n",
    "                                    \"i\": i, \"j\": j,\n",
    "                                    \"M\": M, \"N\": N, \"K\": K,\n",
    "                                    \"tM\": tM, \"tN\": tN, \"tK\": tK,\n",
    "                                    \"pre_shift\": pre_shift_code_block,\n",
    "                                    \"BSP_stride\": BSP_stride,\n",
    "                                    \"BSP_init\": BSP_init_code_block,\n",
    "                                    \"BSP_loop\": BSP_loop_code_block,\n",
    "                                    \"BSP_compute\": BSP_compute_code_block,\n",
    "                                    \"BSP_communication\": BSP_communication_code_block,\n",
    "                                    \"BSP_sync\": BSP_sync,\n",
    "                                    \"post_shift\": post_shift_code_block,})\n",
    "    \n",
    "    return sdfg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "M = dace.symbol(\"M\")\n",
    "N = dace.symbol(\"N\")\n",
    "K = dace.symbol(\"K\")\n",
    "\n",
    "dim_x = 1\n",
    "dim_y = 64\n",
    "cluster_dims = (dim_x, dim_y)\n",
    "k_dims = (1,8)\n",
    "\n",
    "K = 7168\n",
    "M = 64\n",
    "N = 2112\n",
    "\n",
    "tK = 64\n",
    "tM = 64\n",
    "tN = 264\n",
    "\n",
    "A_host = np.ones((M, K), dtype=np.float16)\n",
    "B_host = np.ones((K, N), dtype=np.float16)\n",
    "C_host = np.zeros((M, N), dtype=np.float16)\n",
    "\n",
    "\n",
    "\n",
    "# G = A_host@B_host\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "placement_scheme_A: (24, 25, 26, 27, 28, 29, 30, 31, 24, 25, 26, 27, 28, 29, 30, 31, 24, 25, 26, 27, 28, 29, 30, 31, 24, 25, 26, 27, 28, 29, 30, 31, 24, 25, 26, 27, 28, 29, 30, 31, 24, 25, 26, 27, 28, 29, 30, 31, 24, 25, 26, 27, 28, 29, 30, 31, 24, 25, 26, 27, 28, 29, 30, 31, 24, 25, 26, 27, 28, 29, 30, 31, 24, 25, 26, 27, 28, 29, 30, 31, 24, 25, 26, 27, 28, 29, 30, 31, 24, 25, 26, 27, 28, 29, 30, 31, 24, 25, 26, 27, 28, 29, 30, 31, 24, 25, 26, 27, 28, 29, 30, 31)\n",
      "placement_scheme_B: (0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 7)\n",
      "placement_scheme_C: (0, 1, 2, 3, 4, 5, 6, 7)\n"
     ]
    }
   ],
   "source": [
    "A_handler = InterleaveHandler(array=A_host, block_shape=(tM, tK), cluster_dims=cluster_dims)\n",
    "# A_handler.split_horizental()\n",
    "A_handler.split_to_blocks()\n",
    "A_handler.place_to_range(place_range=(24, 31, 1))\n",
    "split_scheme_A = A_handler.split_scheme\n",
    "placement_scheme_A = A_handler.placement_scheme\n",
    "\n",
    "B_handler = InterleaveHandler(array=B_host, block_shape=(tK, tN), cluster_dims=cluster_dims)\n",
    "# B_handler.split_vertical()\n",
    "B_handler.split_to_blocks()\n",
    "B_handler.place_to_range(place_range=(0, 7, 1))\n",
    "split_scheme_B = B_handler.split_scheme\n",
    "placement_scheme_B = B_handler.placement_scheme\n",
    "\n",
    "\n",
    "C_handler = InterleaveHandler(array=C_host, block_shape=(tM, tN), cluster_dims=cluster_dims)\n",
    "# C_handler.split_vertical()\n",
    "C_handler.split_to_blocks()\n",
    "C_handler.place_to_range(place_range=(0, 7, 1))\n",
    "split_scheme_C = C_handler.split_scheme\n",
    "placement_scheme_C = C_handler.placement_scheme\n",
    "\n",
    "print(f\"placement_scheme_A: {placement_scheme_A}\")\n",
    "print(f\"placement_scheme_B: {placement_scheme_B}\") \n",
    "print(f\"placement_scheme_C: {placement_scheme_C}\")\n",
    "\n",
    "# make_preload_elf_hbm_interleaved_new(\"./output.elf\", [A_handler, B_handler, C_handler])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WCR supported\n",
      "Edge to replace:  accumulator:None  -(C[64*ci + 64*gi + i:64*ci + 64*gi + i + 64, 264*cj + j + 264*floor(gj/8):264*cj + j + 264*floor(gj/8) + 264] (CR: Sum))->  thread_coarsened[ci=0:64:64, cj=0:264:264]:IN_C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/dace4softhier/dace_devel/dace/sdfg/validation.py:538: UserWarning: WARNING: Use of uninitialized transient \"local_A\" in state \"compute\"\n",
      "  warnings.warn('WARNING: Use of uninitialized transient \"%s\" in state \"%s\"' %\n",
      "/scratch/dace4softhier/dace_devel/dace/sdfg/validation.py:538: UserWarning: WARNING: Use of uninitialized transient \"local_B\" in state \"compute\"\n",
      "  warnings.warn('WARNING: Use of uninitialized transient \"%s\" in state \"%s\"' %\n"
     ]
    }
   ],
   "source": [
    "sdfg = _my_gen_matmul_sdfg(hardware_matmul_mnk=(tM, tN, tK),\n",
    "                            global_storage=dace.dtypes.StorageType.SoftHier_HBM,\n",
    "                            local_storage=dace.dtypes.StorageType.SoftHier_TCDM,\n",
    "                            device_schedule=dace.dtypes.ScheduleType.SoftHier_Device,\n",
    "                            thread_group_schedule=dace.dtypes.ScheduleType.SoftHier_Cluster,\n",
    "                            thread_group_dims=cluster_dims,\n",
    "                            k_group_dims=k_dims,\n",
    "                            hbm_split_scheme=[split_scheme_A, split_scheme_B, split_scheme_C],\n",
    "                            hbm_placement_scheme=[placement_scheme_A, placement_scheme_B, placement_scheme_C],\n",
    "                            is_hbm_interleaved=True,\n",
    "                            input_float=dace.float16,\n",
    "                            output_float=dace.float16,\n",
    "                            coarsening_factor=1,\n",
    "                            mmad_tasklet_str=\"flex_redmule_trigger(_in_local_a, _in_local_b, _in_accumulator, REDMULE_FP_16);\")\n",
    "sdfg.save(\"my_gemm.sdfgz\")\n",
    "sdfg.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/dace4softhier/dace_devel/dace/codegen/targets/soft_hier/soft_hier.py:2134: UserWarning: No `gpu_block_size` property specified on map \"gemm_entry\". Falling back to the configuration entry `compiler.cuda.default_block_size`: 32,1,1. You can either specify the block size to use with the gpu_block_size property, or by adding nested `GPU_ThreadBlock` maps, which map work to individual threads. For more information, see https://spcldace.readthedocs.io/en/latest/optimization/gpu.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SoftHier: DMA core map: {'C': 0, 'B': 1, 'A': 2}\n",
      "SoftHier: TCDM HBM map: {'accumulator': 'C', 'local_B': 'B', 'local_A': 'A'}\n",
      "Waring: No `gpu_block_size` property specified on map gemm_entry. \n",
      "RedMule Dims [[1, 64, 64], [1, 64, 264]]\n",
      "Generating NestedSDFG using SoftHierCodeGen\n",
      "Generating Tasklet Using CPU Codegen\n",
      "Generating NestedSDFG using SoftHierCodeGen\n",
      "Generating Tasklet Using CPU Codegen\n",
      "Defining Out Memlet\n",
      "Generating NestedSDFG using SoftHierCodeGen\n",
      "Generating Tasklet Using CPU Codegen\n",
      "SoftHier: DMA core map: {'C': 0, 'B': 1, 'A': 2}\n",
      "SoftHier: TCDM HBM map: {'accumulator': 'C', 'local_B': 'B', 'local_A': 'A'}\n",
      "Waring: No `gpu_block_size` property specified on map gemm_entry. \n",
      "RedMule Dims [[1, 64, 64], [1, 64, 264]]\n",
      "Generating NestedSDFG using SoftHierCodeGen\n",
      "Generating Tasklet Using CPU Codegen\n",
      "Generating NestedSDFG using SoftHierCodeGen\n",
      "Generating Tasklet Using CPU Codegen\n",
      "Defining Out Memlet\n",
      "Generating NestedSDFG using SoftHierCodeGen\n",
      "Generating Tasklet Using CPU Codegen\n",
      "GVSOC_INSTALL_PATH: None\n",
      "GVSOC_DIR: None\n",
      "SOFTHIER_INSTALL_PATH: None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<dace.codegen.compiled_sdfg.CompiledSDFG at 0x7fcf0c517510>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Code\n",
    "Code(sdfg.generate_code()[1].clean_code, language='cpp')\n",
    "sdfg.compile()\n",
    "# sdfg(A=A_host, B=B_host, C=C_host, M=M, N=N, K=K)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sdfg.compile()\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "A_host = np.ones((M, K), dtype=np.float16)\n",
    "B_host = np.ones((K, N), dtype=np.float16)\n",
    "C_host = np.zeros((M, N), dtype=np.float16)\n",
    "for i in range(M):\n",
    "    for j in range(K):\n",
    "        if np.random.rand() < 0.3:\n",
    "            A_host[i, j] = 0.0\n",
    "for i in range(K):\n",
    "    for j in range(N):\n",
    "        if np.random.rand() < 0.3:\n",
    "            B_host[i, j] = 0.0\n",
    "start_address = 0x00000000\n",
    "A_address = 64 + start_address\n",
    "B_address = 64 + A_host.nbytes + start_address\n",
    "C_address = 64 + A_host.nbytes + B_host.nbytes + start_address\n",
    "G_address = 64 + A_host.nbytes + B_host.nbytes + C_host.nbytes + start_address\n",
    "# create a uint32 np array to store the addresses\n",
    "args = np.array([A_address, B_address, C_address, K, M, N, G_address], dtype=np.uint32)\n",
    "# args = make_preload_elf_hbm_interleaved(\"output.elf\", [A_host, B_host, C_host], [split_scheme_A, split_scheme_B, split_scheme_C], [placement_scheme_A, placement_scheme_B, placement_scheme_C], [(64, 32), (32, 16), (64, 16)], start_addresses=[])\n",
    "# G = A_host@B_host\n",
    "# make_preload_elf(\"./output.elf\", [args, A_host, B_host, C_host, G])\n",
    "\n",
    "# make_preload_elf(\"/usr/scratch/badile111/dace4softhier/gvsoc/output.elf\", [args, A_host, B_host, C_host])\n",
    "# print(A_host@B_host)\n",
    "# sdfg(A=A_host, B=B_host, C=C_host, M=M, N=N, K=K)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
