{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script src=\"https://spcl.github.io/dace-webclient/dist/sdfv.js\"></script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import dace\n",
    "import typing\n",
    "import os\n",
    "import numpy as np\n",
    "from dace.transformation.dataflow import DoubleBuffering\n",
    "\n",
    "def make_preload_elf(output_file_path, np_arrays, start_addresses=None):\n",
    "    \"\"\"\n",
    "    Generate an ELF file preloading numpy arrays.\n",
    "\n",
    "    Parameters:\n",
    "    - output_file_path (str): Path to save the output ELF file.\n",
    "    - np_arrays (list of numpy.ndarray): List of numpy arrays to include in the ELF.\n",
    "    - start_addresses (list of int or None): List of starting addresses for each array, or None.\n",
    "      If None, addresses are auto-determined with 64-byte alignment.\n",
    "    \"\"\"\n",
    "    NP_DTYPE_TO_C = {\n",
    "        np.dtype('int8'): 'int8_t',\n",
    "        np.dtype('uint8'): 'uint8_t',\n",
    "        np.dtype('int16'): 'int16_t',\n",
    "        np.dtype('uint16'): 'uint16_t',\n",
    "        np.dtype('int32'): 'int32_t',\n",
    "        np.dtype('uint32'): 'uint32_t',\n",
    "        np.dtype('int64'): 'int64_t',\n",
    "        np.dtype('uint64'): 'uint64_t',\n",
    "        np.dtype('float16'): 'float16',\n",
    "        np.dtype('float32'): 'float',\n",
    "        np.dtype('float64'): 'double',\n",
    "    }\n",
    "    \n",
    "    ENV_PATH = os.environ.get(\"PATH\")\n",
    "    # Add RISC-V toolchain to PATH /scratch/dace4softhier/gvsoc/third_party/toolchain/v1.0.16-pulp-riscv-gcc-centos-7/bin/\n",
    "    os.environ[\"PATH\"] = f\"{ENV_PATH}:/scratch/dace4softhier/gvsoc/third_party/toolchain/v1.0.16-pulp-riscv-gcc-centos-7/bin/\"\n",
    "    \n",
    "    # Handle default for start_addresses\n",
    "    if start_addresses is None:\n",
    "        start_addresses = [None] * len(np_arrays)\n",
    "\n",
    "    # Validate inputs\n",
    "    if len(np_arrays) != len(start_addresses):\n",
    "        raise ValueError(\"np_arrays and start_addresses must have the same length.\")\n",
    "\n",
    "    # 64-byte alignment\n",
    "    alignment = 64\n",
    "    current_address = 0xc0000000  # Default starting address for auto-addressing\n",
    "\n",
    "    # Step 1: Create \"array.c\"\n",
    "    array_c_content = ['#include <stdint.h>']\n",
    "    section_names = []\n",
    "\n",
    "    for idx, (array, start_addr) in enumerate(zip(np_arrays, start_addresses)):\n",
    "        # Determine C type from NumPy dtype\n",
    "        c_type = NP_DTYPE_TO_C.get(array.dtype, None)\n",
    "        if c_type is None:\n",
    "            raise TypeError(f\"Unsupported NumPy dtype: {array.dtype}\")\n",
    "\n",
    "        section_name = f\".custom_section_{idx}\"\n",
    "        section_names.append(section_name)\n",
    "        \n",
    "        if start_addr is None:\n",
    "            # Auto-determine the address with alignment\n",
    "            start_addr = (current_address + alignment - 1) & ~(alignment - 1)\n",
    "        else:\n",
    "            # Ensure provided addresses are aligned\n",
    "            if start_addr % alignment != 0:\n",
    "                raise ValueError(f\"Provided address {start_addr} is not {alignment}-byte aligned.\")\n",
    "\n",
    "        # Generate the array definition\n",
    "        array_values = \", \".join(map(str, array.flatten()))\n",
    "        array_c_content.append(\n",
    "            f'{c_type} array_{idx}[] __attribute__((section(\"{section_name}\"))) = {{{array_values}}};'\n",
    "        )\n",
    "\n",
    "        current_address = start_addr + array.nbytes\n",
    "\n",
    "    array_c_code = \"\\n\".join(array_c_content)\n",
    "\n",
    "    with open(\"array.c\", \"w\") as f:\n",
    "        f.write(array_c_code)\n",
    "\n",
    "\n",
    "    # Step 2: Create \"link.ld\"\n",
    "    link_ld_content = [\"SECTIONS {\"]\n",
    "    current_address = 0xc0000000  # Reset for linker script auto-addressing\n",
    "\n",
    "    for idx, (array, start_addr) in enumerate(zip(np_arrays, start_addresses)):\n",
    "        section_name = section_names[idx]\n",
    "\n",
    "        if start_addr is None:\n",
    "            # Auto-determine the address with alignment\n",
    "            start_addr = (current_address + alignment - 1) & ~(alignment - 1)\n",
    "        link_ld_content.append(\n",
    "            f\"    . = 0x{start_addr:X};\\n    {section_name} : {{ *({section_name}) }}\"\n",
    "        )\n",
    "        current_address = start_addr + array.nbytes\n",
    "\n",
    "    link_ld_content.append(\"}\")\n",
    "    link_ld_code = \"\\n\".join(link_ld_content)\n",
    "\n",
    "    with open(\"link.ld\", \"w\") as f:\n",
    "        f.write(link_ld_code)\n",
    "\n",
    "    # Step 3: Compile the ELF file\n",
    "    os.system(\"riscv32-unknown-elf-gcc -c array.c -o array.o\")\n",
    "    os.system(f\"riscv32-unknown-elf-ld -T link.ld array.o -o {output_file_path}\")\n",
    "    os.system(f\"riscv32-unknown-elf-strip --remove-section=.comment --remove-section=.Pulp_Chip.Info {output_file_path}\")\n",
    "\n",
    "    # Step 4: Cleanup\n",
    "    os.remove(\"array.c\")\n",
    "    os.remove(\"link.ld\")\n",
    "    os.remove(\"array.o\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gen_matmul_sdfg(hardware_matmul_mnk: typing.Tuple,\n",
    "                     global_storage: dace.dtypes.StorageType,\n",
    "                     local_storage: dace.dtypes.StorageType,\n",
    "                     device_schedule: dace.dtypes.ScheduleType,\n",
    "                     thread_group_schedule: dace.dtypes.ScheduleType,\n",
    "                     thread_group_dims: typing.Tuple,\n",
    "                     input_float,\n",
    "                     output_float,\n",
    "                     coarsening_factor,\n",
    "                     mmad_tasklet_str: str):\n",
    "    sdfg = dace.SDFG(\"GEMM\")\n",
    "    tM, tN, tK = hardware_matmul_mnk\n",
    "    tM *= coarsening_factor\n",
    "    tN *= coarsening_factor\n",
    "    tK *= coarsening_factor\n",
    "    gM, gN = thread_group_dims\n",
    "\n",
    "    main_state = sdfg.add_state(\"main\")\n",
    "    state = main_state\n",
    "\n",
    "    arrs = dict()\n",
    "    for arr_name, shape, ftype in [(\"A\", (M, N), input_float), (\"B\", (K, N), input_float), (\"C\", (M, N), output_float)]:\n",
    "        arrn, arr = sdfg.add_array(name=arr_name, shape=shape, dtype=ftype, storage=global_storage, transient=False)\n",
    "        arrs[arrn] = arr\n",
    "    arrn, arr = sdfg.add_array(name=\"accumulator\", shape=(tM//coarsening_factor, tN//coarsening_factor), dtype=ftype, storage=local_storage, transient=True)\n",
    "    arrs[arrn] = arr\n",
    "\n",
    "    dev_map_entry, dev_map_exit = main_state.add_map(\n",
    "        name=\"gemm_entry\",\n",
    "        ndrange={\"i\" : dace.subsets.Range([(0, M-1, tM*gM)]),\n",
    "                 \"j\" : dace.subsets.Range([(0, N-1, tN*gN)])},\n",
    "        schedule=device_schedule\n",
    "    )\n",
    "    for name in [\"A\", \"B\", \"C\"]:\n",
    "        access_str = \", \".join([f\"0:{n}\" for n in arrs[name].shape])\n",
    "        an = state.add_access(name)\n",
    "        state.add_edge(an, None, dev_map_entry, f\"IN_{name}\", dace.memlet.Memlet(f\"{name}[{access_str}]\"))\n",
    "        dev_map_entry.add_in_connector(f\"IN_{name}\")\n",
    "        if name == \"C\":\n",
    "            dev_map_exit.add_out_connector(f\"OUT_{name}\")\n",
    "            anc3 = state.add_access(name)\n",
    "            state.add_edge(dev_map_exit, f\"OUT_{name}\", anc3, None, dace.memlet.Memlet(f\"{name}[{access_str}]\"))\n",
    "\n",
    "    thread_group_map_entry, thread_group_map_exit = main_state.add_map(\n",
    "        name=\"thread_group_mmad\",\n",
    "        ndrange={\"gi\" : dace.subsets.Range([(0, gM-1, 1)]),\n",
    "                 \"gj\" : dace.subsets.Range([(0, gM-1, 1)])},\n",
    "        schedule=device_schedule\n",
    "    )\n",
    "\n",
    "    for name in [\"A\", \"B\", \"C\"]:\n",
    "        if name == \"A\":\n",
    "            access_str = \", \".join([f\"i:i + {tM} * {gM}\", \"0:K\"])\n",
    "        elif name == \"B\":\n",
    "            access_str = \", \".join([\"0:K\", f\"j:j + {tN} * {gN}\"])\n",
    "        elif name == \"C\":\n",
    "            access_str = \", \".join([f\"i:i + {tgdim} * {processing_elems}\" for tgdim, processing_elems in zip(thread_group_dims, [tM, tN])])\n",
    "        state.add_edge(dev_map_entry, f\"OUT_{name}\", thread_group_map_entry, f\"IN_{name}\", dace.memlet.Memlet(f\"{name}[{access_str}]\"))\n",
    "        dev_map_entry.add_out_connector(f\"OUT_{name}\")\n",
    "        thread_group_map_entry.add_in_connector(f\"IN_{name}\")\n",
    "        if name == \"C\":\n",
    "            state.add_edge(thread_group_map_exit, f\"OUT_{name}\", dev_map_exit, f\"IN_{name}\", dace.memlet.Memlet(f\"{name}[{access_str}]\"))\n",
    "            dev_map_exit.add_in_connector(f\"IN_{name}\")\n",
    "            thread_group_map_exit.add_out_connector(f\"OUT_{name}\")\n",
    "\n",
    "    thread_coarsened_map_entry, thread_coarsened_map_exit = main_state.add_map(\n",
    "        name=\"thread_coarsened\",\n",
    "        ndrange={\"ci\" : dace.subsets.Range([(0, tM-1, tM//coarsening_factor)]),\n",
    "                 \"cj\" : dace.subsets.Range([(0, tN-1, tN//coarsening_factor)])},\n",
    "        schedule=dace.dtypes.ScheduleType.Sequential\n",
    "    )\n",
    "\n",
    "    for name in [\"A\", \"B\", \"C\"]:\n",
    "        if name == \"A\":\n",
    "            access_str = \", \".join([f\"i + ci * {tM}:i + ci * {tM} + {tM}\", \"0:K\"])\n",
    "        elif name == \"B\":\n",
    "            access_str = \", \".join([\"0:K\", f\"j + cj * {tN}:j + cj * {tN} + {tN}\"])\n",
    "        elif name == \"C\":\n",
    "            access_str = \", \".join([f\"i:i + {tgdim} * {processing_elems}\" for tgdim, processing_elems in zip(thread_group_dims, [tM, tN])])\n",
    "        state.add_edge(thread_group_map_entry, f\"OUT_{name}\", thread_coarsened_map_entry, f\"IN_{name}\", dace.memlet.Memlet(f\"{name}[{access_str}]\"))\n",
    "        thread_group_map_entry.add_out_connector(f\"OUT_{name}\")\n",
    "        thread_coarsened_map_entry.add_in_connector(f\"IN_{name}\")\n",
    "        if name == \"C\":\n",
    "            state.add_edge(thread_coarsened_map_exit, f\"OUT_{name}\", thread_group_map_exit, f\"IN_{name}\", dace.memlet.Memlet(f\"{name}[{access_str}]\"))\n",
    "            thread_group_map_exit.add_in_connector(f\"IN_{name}\")\n",
    "            thread_coarsened_map_exit.add_out_connector(f\"OUT_{name}\")\n",
    "\n",
    "    block_tiled_map_entry, block_tiled_map_exit = main_state.add_map(\n",
    "        name=\"block_tiled\",\n",
    "        ndrange={\"bk\" : dace.subsets.Range([(0, K-1, tK//coarsening_factor)])},\n",
    "        schedule=dace.dtypes.ScheduleType.Sequential\n",
    "    )\n",
    "\n",
    "    accumulator_an = state.add_access(\"accumulator\")\n",
    "    accumulator_an.setzero = True\n",
    "    state.add_edge(thread_coarsened_map_entry, None, accumulator_an, None, dace.memlet.Memlet(None))\n",
    "    state.add_edge(accumulator_an, None, block_tiled_map_entry, f\"IN_accumulator\", dace.memlet.Memlet(f\"accumulator[0:{tM//coarsening_factor}, 0:{tN//coarsening_factor}]\"))\n",
    "    block_tiled_map_entry.add_in_connector(\"IN_accumulator\")\n",
    "    thread_group_map_entry\n",
    "\n",
    "\n",
    "    for name in [\"A\", \"B\"]:\n",
    "        if name == \"A\":\n",
    "            access_str = \", \".join([f\"i + ci * {tM//coarsening_factor}:i + ci * {tM//coarsening_factor} + {tM//coarsening_factor}\", \"0:K\"])\n",
    "        elif name == \"B\":\n",
    "            access_str = \", \".join([\"0:K\", f\"j + cj * {tN//coarsening_factor}:j + cj * {tN//coarsening_factor} + {tN//coarsening_factor}\"])\n",
    "\n",
    "        state.add_edge(thread_coarsened_map_entry, f\"OUT_{name}\", block_tiled_map_entry, f\"IN_{name}\", dace.memlet.Memlet(f\"{name}[{access_str}]\"))\n",
    "        block_tiled_map_entry.add_in_connector(f\"IN_{name}\")\n",
    "        thread_coarsened_map_entry.add_out_connector(f\"OUT_{name}\")\n",
    "\n",
    "\n",
    "    # Load\n",
    "    local_access_nodes = dict()\n",
    "    for name, shape in [(\"A\", (tM//coarsening_factor, tK//coarsening_factor)), (\"B\", (tK//coarsening_factor, tN//coarsening_factor))]:\n",
    "        block_tiled_map_entry.add_out_connector(f\"OUT_{name}\")\n",
    "        arrn, arr = sdfg.add_array(name=f\"local_{name}\", shape=shape, dtype=input_float, storage=local_storage, transient=True)\n",
    "        arrs[arrn] = arr\n",
    "        an = state.add_access(f\"local_{name}\")\n",
    "        local_access_nodes[f\"local_{name}\"] = an\n",
    "        if name == \"A\":\n",
    "            access_str = \", \".join([f\"i + ci * {tM//coarsening_factor}:i + ci * {tM//coarsening_factor} + {tM//coarsening_factor}\", f\"bK:bK+{tK//coarsening_factor}\"])\n",
    "        elif name == \"B\":\n",
    "            access_str = \", \".join([f\"bK:bK+{tK//coarsening_factor}\", f\"j + cj * {tN//coarsening_factor}:j + cj * {tN//coarsening_factor} + {tN//coarsening_factor}\"])\n",
    "        state.add_edge(block_tiled_map_entry, f\"OUT_{name}\", an, None, dace.memlet.Memlet(f\"{name}[{access_str}]\"))\n",
    "\n",
    "    # Connect local_A + local_B -> matmul -> accumulator\n",
    "    matmul_tasklet = state.add_tasklet(name=\"mmad\", inputs={\"_in_local_a\", \"_in_local_b\", \"_in_accumulator\"}, outputs={\"_out_accumulator\"},\n",
    "                                       code=mmad_tasklet_str, language=dace.dtypes.Language.CPP)\n",
    "\n",
    "    #for name in [\"local_A\", \"local_B\", \"accumulate\"]:\n",
    "    #    state.add_edge()\n",
    "\n",
    "    for name, an in local_access_nodes.items():\n",
    "        state.add_edge(an, None, matmul_tasklet, \"_in_\" + name.lower(), dace.memlet.Memlet(name))\n",
    "    state.add_edge(block_tiled_map_entry, f\"OUT_accumulator\", matmul_tasklet, \"_in_accumulator\", dace.memlet.Memlet(\"accumulator\"))\n",
    "    accumulator_an2 = state.add_access(\"accumulator\")\n",
    "    state.add_edge(matmul_tasklet, f\"_out_accumulator\", accumulator_an2, None, dace.memlet.Memlet(\"accumulator\"))\n",
    "    state.add_edge(accumulator_an2, None, block_tiled_map_exit, \"IN_accumulator\", dace.memlet.Memlet(\"accumulator\"))\n",
    "    #state.add_edge(matmul_tasklet, \"_out_accumulator\", block_tiled_map_exit, \"IN_accumulator\", dace.memlet.Memlet(\"accumulator\"))\n",
    "    block_tiled_map_exit.add_in_connector(\"IN_accumulator\")\n",
    "    block_tiled_map_entry.add_out_connector(\"OUT_accumulator\")\n",
    "    block_tiled_map_exit.add_out_connector(\"OUT_accumulator\")\n",
    "\n",
    "\n",
    "    assign_tasklet = state.add_tasklet(name=\"assign\", inputs={\"_in_accumulator\", \"_in_C\"}, outputs={\"_out_C\"}, code=\"_out_C = _in_accumulator\")\n",
    "    #state.add_edge(block_tiled_map_exit, \"OUT_accumulator\", assign_tasklet, \"_in_accumulator\", dace.memlet.Memlet(\"accumulator\"))\n",
    "\n",
    "    accumulator_an3 = state.add_access(\"accumulator\")\n",
    "    state.add_edge(block_tiled_map_exit, f\"OUT_accumulator\", accumulator_an3, None, dace.memlet.Memlet(\"accumulator\"))\n",
    "    state.add_edge(accumulator_an3, None, assign_tasklet, \"_in_accumulator\", dace.memlet.Memlet(\"accumulator\"))\n",
    "    state.add_edge(thread_coarsened_map_entry, \"OUT_C\", assign_tasklet, \"_in_C\", dace.memlet.Memlet())\n",
    "\n",
    "    c_an2 = state.add_access(\"C\")\n",
    "    access_str = \", \".join([f\"i:i + {tgdim} * {processing_elems}\" for tgdim, processing_elems in zip(thread_group_dims, [tM//coarsening_factor, tN//coarsening_factor])])\n",
    "    state.add_edge(assign_tasklet, \"_out_C\", c_an2, None, dace.memlet.Memlet(f\"C[{access_str}]\"))\n",
    "    thread_coarsened_map_entry.add_out_connector(f\"OUT_C\")\n",
    "    state.add_edge(c_an2, None, thread_coarsened_map_exit, \"IN_C\", dace.memlet.Memlet(f\"C[{access_str}]\"))\n",
    "    thread_coarsened_map_exit.add_in_connector(\"IN_C\")\n",
    "\n",
    "    return sdfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "M = dace.symbol(\"M\")\n",
    "N = dace.symbol(\"N\")\n",
    "K = dace.symbol(\"K\")\n",
    "\n",
    "def _my_gen_matmul_sdfg(hardware_matmul_mnk: typing.Tuple,\n",
    "                     global_storage: dace.dtypes.StorageType,\n",
    "                     local_storage: dace.dtypes.StorageType,\n",
    "                     device_schedule: dace.dtypes.ScheduleType,\n",
    "                     thread_group_schedule: dace.dtypes.ScheduleType,\n",
    "                     thread_group_dims: typing.Tuple,\n",
    "                     input_float,\n",
    "                     output_float,\n",
    "                     coarsening_factor,\n",
    "                     mmad_tasklet_str: str):\n",
    "    sdfg = dace.SDFG(\"GEMM\")\n",
    "    tM, tN, tK = hardware_matmul_mnk\n",
    "    tM *= coarsening_factor\n",
    "    tN *= coarsening_factor\n",
    "    tK *= coarsening_factor\n",
    "    gM, gN = thread_group_dims\n",
    "\n",
    "    main_state = sdfg.add_state(\"main\")\n",
    "    state = main_state\n",
    "\n",
    "    arrs = dict()\n",
    "    for arr_name, shape, ftype in [(\"A\", (M, K), input_float), (\"B\", (K, N), input_float), (\"C\", (M, N), output_float)]:\n",
    "        arrn, arr = sdfg.add_array(name=arr_name, shape=shape, dtype=ftype, storage=global_storage, transient=False)\n",
    "        arrs[arrn] = arr\n",
    "    arrn, arr = sdfg.add_array(name=\"accumulator\", shape=(coarsening_factor*coarsening_factor, tM//coarsening_factor, tN//coarsening_factor), dtype=ftype, storage=local_storage, transient=True)\n",
    "    arrs[arrn] = arr\n",
    "\n",
    "    dev_map_entry, dev_map_exit = main_state.add_map(\n",
    "        name=\"gemm_entry\",\n",
    "        ndrange={\"i\" : dace.subsets.Range([(0, M-1, tM*gM)]),\n",
    "                 \"j\" : dace.subsets.Range([(0, N-1, tN*gN)])},\n",
    "        schedule=device_schedule\n",
    "    )\n",
    "    for name in [\"A\", \"B\", \"C\"]:\n",
    "    # for name in [\"A\", \"B\"]:\n",
    "        if name == \"A\" or name == \"B\":\n",
    "            access_str = \", \".join([f\"0:{n}\" for n in arrs[name].shape])\n",
    "            an = state.add_access(name)\n",
    "            state.add_edge(an, None, dev_map_entry, f\"IN_{name}\", dace.memlet.Memlet(f\"{name}[{access_str}]\"))\n",
    "            dev_map_entry.add_in_connector(f\"IN_{name}\")\n",
    "        if name == \"C\":\n",
    "            access_str = \", \".join([f\"0:{n}\" for n in arrs[name].shape])\n",
    "            # an = state.add_access(name)\n",
    "            dev_map_exit.add_out_connector(f\"OUT_{name}\")\n",
    "            anc3 = state.add_access(name)\n",
    "            state.add_edge(dev_map_exit, f\"OUT_{name}\", anc3, None, dace.memlet.Memlet(f\"{name}[{access_str}]\"))\n",
    "\n",
    "    thread_group_map_entry, thread_group_map_exit = main_state.add_map(\n",
    "        name=\"thread_group_mmad\",\n",
    "        ndrange={\"gi\" : dace.subsets.Range([(0, gM-1, 1)]),\n",
    "                 \"gj\" : dace.subsets.Range([(0, gM-1, 1)])},\n",
    "        schedule=thread_group_schedule\n",
    "    )\n",
    "\n",
    "    for name in [\"A\", \"B\", \"C\"]:\n",
    "        if name == \"A\" or name == \"B\":\n",
    "            if name == \"A\":\n",
    "                access_str = \", \".join([f\"i:i + {tM} * {gM}\", \"0:K\"])\n",
    "            elif name == \"B\":\n",
    "                access_str = \", \".join([\"0:K\", f\"j:j + {tN} * {gN}\"])\n",
    "            elif name == \"C\":\n",
    "                access_str = \", \".join([f\"i:i + {gM} * {tM}\", f\"j:j + {gN} * {tN}\"])\n",
    "            state.add_edge(dev_map_entry, f\"OUT_{name}\", thread_group_map_entry, f\"IN_{name}\", dace.memlet.Memlet(f\"{name}[{access_str}]\"))\n",
    "            dev_map_entry.add_out_connector(f\"OUT_{name}\")\n",
    "            thread_group_map_entry.add_in_connector(f\"IN_{name}\")\n",
    "        if name == \"C\":\n",
    "            access_str = \", \".join([f\"i:i + {gM} * {tM}\", f\"j:j + {gN} * {tN}\"])\n",
    "            state.add_edge(thread_group_map_exit, f\"OUT_{name}\", dev_map_exit, f\"IN_{name}\", dace.memlet.Memlet(f\"{name}[{access_str}]\"))\n",
    "            dev_map_exit.add_in_connector(f\"IN_{name}\")\n",
    "            thread_group_map_exit.add_out_connector(f\"OUT_{name}\")\n",
    "\n",
    "    thread_coarsened_map_entry, thread_coarsened_map_exit = main_state.add_map(\n",
    "        name=\"thread_coarsened\",\n",
    "        ndrange={\"ci\" : dace.subsets.Range([(0, tM-1, tM//coarsening_factor)]),\n",
    "                 \"cj\" : dace.subsets.Range([(0, tN-1, tN//coarsening_factor)])},\n",
    "        schedule=dace.dtypes.ScheduleType.SoftHier_Sequential\n",
    "    )\n",
    "\n",
    "    for name in [\"A\", \"B\", \"C\"]:\n",
    "        if name == \"A\" or name == \"B\":\n",
    "                if name == \"A\":\n",
    "                    access_str = \", \".join([f\"i + gi * {tM}:i + gi * {tM} + {tM}\", \"0:K\"])\n",
    "                elif name == \"B\":\n",
    "                    access_str = \", \".join([\"0:K\", f\"j + gj * {tN}:j + gj * {tN} + {tN}\"])\n",
    "                elif name == \"C\":\n",
    "                    access_str = \", \".join([f\"i + gj * {tM}:i + gj * {tM} + {tM}\", f\"j + gj * {tN}:j + gj * {tN} + {tN}\"])\n",
    "                state.add_edge(thread_group_map_entry, f\"OUT_{name}\", thread_coarsened_map_entry, f\"IN_{name}\", dace.memlet.Memlet(f\"{name}[{access_str}]\"))\n",
    "                thread_group_map_entry.add_out_connector(f\"OUT_{name}\")\n",
    "                thread_coarsened_map_entry.add_in_connector(f\"IN_{name}\")\n",
    "        if name == \"C\":\n",
    "            access_str = \", \".join([f\"i + gj * {tM}:i + gj * {tM} + {tM}\", f\"j + gj * {tN}:j + gj * {tN} + {tN}\"])\n",
    "            state.add_edge(thread_coarsened_map_exit, f\"OUT_{name}\", thread_group_map_exit, f\"IN_{name}\", dace.memlet.Memlet(f\"{name}[{access_str}]\"))\n",
    "            thread_group_map_exit.add_in_connector(f\"IN_{name}\")\n",
    "            thread_coarsened_map_exit.add_out_connector(f\"OUT_{name}\")\n",
    "\n",
    "    block_tiled_map_entry, block_tiled_map_exit = main_state.add_map(\n",
    "        name=\"block_tiled\",\n",
    "        ndrange={\"bK\" : dace.subsets.Range([(0, K-1, tK//coarsening_factor)])},\n",
    "        schedule=dace.dtypes.ScheduleType.SoftHier_Sequential\n",
    "    )\n",
    "\n",
    "    accumulator_an = state.add_access(\"accumulator\")\n",
    "    accumulator_an.setzero = True\n",
    "    state.add_edge(thread_coarsened_map_entry, None, accumulator_an, None, dace.memlet.Memlet(None))\n",
    "    access_str = \", \".join([f\"0:{coarsening_factor}*{coarsening_factor}\", f\"0:{tM//coarsening_factor}\", f\"0:{tN//coarsening_factor}\"])\n",
    "    state.add_edge(accumulator_an, None, block_tiled_map_entry, f\"IN_accumulator\", dace.memlet.Memlet(f\"accumulator[{access_str}]\"))\n",
    "    block_tiled_map_entry.add_in_connector(\"IN_accumulator\")\n",
    "    thread_group_map_entry\n",
    "\n",
    "\n",
    "    for name in [\"A\", \"B\"]:\n",
    "        if name == \"A\":\n",
    "            access_str = \", \".join([f\"i + gi * {tM} + ci * {tM//coarsening_factor}:i + gi * {tM} + ci * {tM//coarsening_factor} + {tM//coarsening_factor}\", \"0:K\"])\n",
    "        elif name == \"B\":\n",
    "            access_str = \", \".join([\"0:K\", f\"j + gj * {tN} + cj * {tN//coarsening_factor}:j + gj * {tN} + cj * {tN//coarsening_factor} + {tN//coarsening_factor}\"])\n",
    "\n",
    "        state.add_edge(thread_coarsened_map_entry, f\"OUT_{name}\", block_tiled_map_entry, f\"IN_{name}\", dace.memlet.Memlet(f\"{name}[{access_str}]\"))\n",
    "        block_tiled_map_entry.add_in_connector(f\"IN_{name}\")\n",
    "        thread_coarsened_map_entry.add_out_connector(f\"OUT_{name}\")\n",
    "\n",
    "\n",
    "    # Load\n",
    "    local_access_nodes = dict()\n",
    "    for name, shape in [(\"A\", (tM//coarsening_factor, tK//coarsening_factor)), (\"B\", (tK//coarsening_factor, tN//coarsening_factor))]:\n",
    "        block_tiled_map_entry.add_out_connector(f\"OUT_{name}\")\n",
    "        arrn, arr = sdfg.add_array(name=f\"local_{name}\", shape=shape, dtype=input_float, storage=local_storage, transient=True)\n",
    "        arrs[arrn] = arr\n",
    "        an = state.add_access(f\"local_{name}\")\n",
    "        local_access_nodes[f\"local_{name}\"] = an\n",
    "        if name == \"A\":\n",
    "            access_str = \", \".join([f\"i + gi * {tM} + ci * {tM//coarsening_factor}:i + gi * {tM} + ci * {tM//coarsening_factor} + {tM//coarsening_factor}\", \n",
    "                                    f\"bK:bK+{tK//coarsening_factor}\"])\n",
    "        elif name == \"B\":\n",
    "            access_str = \", \".join([f\"bK:bK+{tK//coarsening_factor}\", \n",
    "                                    f\"j + gj * {tN} + cj * {tN//coarsening_factor}:j + gj * {tN} + cj * {tN//coarsening_factor} + {tN//coarsening_factor}\"])\n",
    "        state.add_edge(block_tiled_map_entry, f\"OUT_{name}\", an, None, dace.memlet.Memlet(f\"{name}[{access_str}]\"))\n",
    "\n",
    "    # Connect local_A + local_B -> matmul -> accumulator\n",
    "    matmul_tasklet = state.add_tasklet(name=\"mmad_redmule\", inputs={\"_in_local_a\", \"_in_local_b\", \"_in_accumulator\"}, outputs={\"_out_accumulator\"},\n",
    "                                       code=mmad_tasklet_str, language=dace.dtypes.Language.CPP)\n",
    "\n",
    "    #for name in [\"local_A\", \"local_B\", \"accumulate\"]:\n",
    "    #    state.add_edge()\n",
    "\n",
    "    for name, an in local_access_nodes.items():\n",
    "        state.add_edge(an, None, matmul_tasklet, \"_in_\" + name.lower(), dace.memlet.Memlet(name))\n",
    "    state.add_edge(block_tiled_map_entry, f\"OUT_accumulator\", matmul_tasklet, \"_in_accumulator\", dace.memlet.Memlet(\"accumulator\"))\n",
    "    # accumulator_an2 = state.add_access(\"accumulator\")\n",
    "    # state.add_edge(matmul_tasklet, f\"_out_accumulator\", accumulator_an2, None, dace.memlet.Memlet(\"accumulator\"))\n",
    "    # state.add_edge(accumulator_an2, None, block_tiled_map_exit, \"IN_accumulator\", dace.memlet.Memlet(\"accumulator\"))\n",
    "    access_str = \", \".join([f\"0:{coarsening_factor}*{coarsening_factor}\", f\"0:{tM//coarsening_factor}\", f\"0:{tN//coarsening_factor}\"])\n",
    "    state.add_edge(matmul_tasklet, \"_out_accumulator\", block_tiled_map_exit, \"IN_accumulator\", dace.memlet.Memlet(f\"accumulator[{access_str}]\"))\n",
    "    block_tiled_map_entry.add_in_connector(\"IN_accumulator\")\n",
    "    block_tiled_map_exit.add_in_connector(\"IN_accumulator\")\n",
    "    block_tiled_map_entry.add_out_connector(\"OUT_accumulator\")\n",
    "    block_tiled_map_exit.add_out_connector(\"OUT_accumulator\")\n",
    "\n",
    "\n",
    "    # assign_tasklet = state.add_tasklet(name=\"assign\", inputs={\"_in_accumulator\"}, outputs={\"_out_C\"}, code=\"_out_C = _in_accumulator\")\n",
    "    # state.add_edge(block_tiled_map_exit, \"OUT_C\", assign_tasklet, \"_in_accumulator\", dace.memlet.Memlet(\"accumulator\")) , \"_in_C\"\n",
    "\n",
    "    # accumulator_an3 = state.add_access(\"accumulator\")\n",
    "    # state.add_edge(block_tiled_map_exit, f\"OUT_accumulator\", accumulator_an3, None, dace.memlet.Memlet(\"accumulator\"))\n",
    "    # state.add_edge(accumulator_an3, None, assign_tasklet, \"_in_accumulator\", dace.memlet.Memlet(\"accumulator\"))\n",
    "    # state.add_edge(block_tiled_map_exit, f\"OUT_accumulator\", assign_tasklet, \"_in_accumulator\", dace.memlet.Memlet())\n",
    "\n",
    "    # c_an2 = state.add_access(\"C\")\n",
    "    accumulator_an3 = state.add_access(\"accumulator\")\n",
    "    \n",
    "    # state.add_edge(assign_tasklet, \"_out_C\", c_an2, None, dace.memlet.Memlet(f\"C[{access_str}]\"))\n",
    "    # thread_coarsened_map_entry.add_out_connector(f\"OUT_C\")\n",
    "    # state.add_edge(c_an2, None, thread_coarsened_map_exit, \"IN_C\", dace.memlet.Memlet(f\"C[{access_str}]\"))\n",
    "    # state.add_edge(assign_tasklet, \"_out_C\", thread_coarsened_map_exit, \"IN_C\", dace.memlet.Memlet(f\"C[{access_str}]\"))\n",
    "    # state.add_edge(block_tiled_map_exit, f\"OUT_accumulator\", thread_coarsened_map_exit, \"IN_C\", dace.memlet.Memlet(f\"C[{access_str}]\"))\n",
    "    access_str = \", \".join([f\"0:{coarsening_factor}*{coarsening_factor}\", f\"0:{tM//coarsening_factor}\", f\"0:{tN//coarsening_factor}\"])\n",
    "    state.add_edge(block_tiled_map_exit, f\"OUT_accumulator\", accumulator_an3, None, dace.memlet.Memlet(f\"accumulator[{access_str}]\"))\n",
    "    access_str = \", \".join([f\"i + gi * {tM} + ci * {tM//coarsening_factor}:i + gi * {tM} + ci * {tM//coarsening_factor} + {tM//coarsening_factor}\", \n",
    "                            f\"j + gj * {tN} + cj * {tN//coarsening_factor}:j + gj * {tN} + cj * {tN//coarsening_factor} + {tN//coarsening_factor}\"])\n",
    "    state.add_edge(accumulator_an3, None, thread_coarsened_map_exit, \"IN_C\", dace.memlet.Memlet(f\"C[{access_str}]\"))\n",
    "    thread_coarsened_map_exit.add_in_connector(\"IN_C\")\n",
    "\n",
    "    # DoubleBuffering.apply_to(sdfg, map_entry=block_tiled_map_entry, transient=local_access_nodes[\"local_A\"])\n",
    "    return sdfg\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    sdfg = _my_gen_matmul_sdfg(hardware_matmul_mnk=(64, 64, 64),\n",
    "                            global_storage=dace.dtypes.StorageType.SoftHier_HBM,\n",
    "                            local_storage=dace.dtypes.StorageType.SoftHier_TCDM,\n",
    "                            device_schedule=dace.dtypes.ScheduleType.SoftHier_Device,\n",
    "                            thread_group_schedule=dace.dtypes.ScheduleType.SoftHier_Cluster,\n",
    "                            thread_group_dims=(4, 4),\n",
    "                            input_float=dace.float16,\n",
    "                            output_float=dace.float16,\n",
    "                            coarsening_factor=1,\n",
    "                            mmad_tasklet_str=\"flex_redmule_trigger(_in_local_a, _in_local_b, _in_accumulator, REDMULE_FP_16);\")\n",
    "    sdfg.save(\"my_gemm.sdfgz\")\n",
    "    sdfg.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waring: No `gpu_block_size` property specified on map gemm_entry. \n",
      "RedMule Dims [[64, 64], [64, 64]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/dace4softhier/dace_devel/dace/codegen/targets/soft_hier/soft_hier.py:2096: UserWarning: No `gpu_block_size` property specified on map \"gemm_entry\". Falling back to the configuration entry `compiler.cuda.default_block_size`: 32,1,1. You can either specify the block size to use with the gpu_block_size property, or by adding nested `GPU_ThreadBlock` maps, which map work to individual threads. For more information, see https://spcldace.readthedocs.io/en/latest/optimization/gpu.html\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GVSOC_INSTALL_PATH: None\n",
      "GVSOC_DIR: None\n",
      "SOFTHIER_INSTALL_PATH: None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<dace.codegen.compiled_sdfg.CompiledSDFG at 0x7f4b355243d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from IPython.display import Code\n",
    "# Code(sdfg.generate_code()[1].clean_code, language='cpp')\n",
    "sdfg.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sdfg.compile()\n",
    "start_address = 0x00000000\n",
    "K = 512\n",
    "M = 512\n",
    "N = 512\n",
    "# A_host = np.random.rand(M, K).astype(np.float16)\n",
    "# B_host = np.random.rand(K, N).astype(np.float16)\n",
    "A_host = np.ones((M, K), dtype=np.float16)\n",
    "B_host = np.ones((K, N), dtype=np.float16)\n",
    "C_host = np.zeros((M, N), dtype=np.float16)\n",
    "\n",
    "A_address = 64 + start_address\n",
    "B_address = 64 + A_host.nbytes + start_address\n",
    "C_address = 64 + A_host.nbytes + B_host.nbytes + start_address\n",
    "# create a uint32 np array to store the addresses\n",
    "args = np.array([A_address, B_address, C_address, K, M, N], dtype=np.uint32)\n",
    "\n",
    "# make_preload_elf(\"/usr/scratch/badile111/dace4softhier/gvsoc/output.elf\", [args, A_host, B_host, C_host])\n",
    "# make_preload_elf(\"/usr/scratch/badile111/dace4softhier/gvsoc/output.elf\", [args])\n",
    "# print(A_host@B_host)\n",
    "# sdfg(A=A_host, B=B_host, C=C_host, M=M, N=N, K=K)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
