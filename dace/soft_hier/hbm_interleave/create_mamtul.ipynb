{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dace\n",
    "import typing\n",
    "import os\n",
    "import numpy as np\n",
    "from dace.transformation.dataflow import DoubleBuffering\n",
    "\n",
    "def make_preload_elf(output_file_path, np_arrays, start_addresses=None):\n",
    "    \"\"\"\n",
    "    Generate an ELF file preloading numpy arrays.\n",
    "\n",
    "    Parameters:\n",
    "    - output_file_path (str): Path to save the output ELF file.\n",
    "    - np_arrays (list of numpy.ndarray): List of numpy arrays to include in the ELF.\n",
    "    - start_addresses (list of int or None): List of starting addresses for each array, or None.\n",
    "      If None, addresses are auto-determined with 64-byte alignment.\n",
    "    \"\"\"\n",
    "    NP_DTYPE_TO_C = {\n",
    "        np.dtype('int8'): 'int8_t',\n",
    "        np.dtype('uint8'): 'uint8_t',\n",
    "        np.dtype('int16'): 'int16_t',\n",
    "        np.dtype('uint16'): 'uint16_t',\n",
    "        np.dtype('int32'): 'int32_t',\n",
    "        np.dtype('uint32'): 'uint32_t',\n",
    "        np.dtype('int64'): 'int64_t',\n",
    "        np.dtype('uint64'): 'uint64_t',\n",
    "        np.dtype('float16'): 'float16',\n",
    "        np.dtype('float32'): 'float',\n",
    "        np.dtype('float64'): 'double',\n",
    "    }\n",
    "    \n",
    "    ENV_PATH = os.environ.get(\"PATH\")\n",
    "    # Add RISC-V toolchain to PATH /scratch/dace4softhier/gvsoc/third_party/toolchain/v1.0.16-pulp-riscv-gcc-centos-7/bin/\n",
    "    os.environ[\"PATH\"] = f\"{ENV_PATH}:/usr/scratch/badile111/dace4softhier/gvsoc/third_party/toolchain/v1.0.16-pulp-riscv-gcc-centos-7/bin/\"\n",
    "    \n",
    "    # Handle default for start_addresses\n",
    "    if start_addresses is None:\n",
    "        start_addresses = [None] * len(np_arrays)\n",
    "\n",
    "    # Validate inputs\n",
    "    if len(np_arrays) != len(start_addresses):\n",
    "        raise ValueError(\"np_arrays and start_addresses must have the same length.\")\n",
    "\n",
    "    # 64-byte alignment\n",
    "    alignment = 64\n",
    "    current_address = 0xc0000000  # Default starting address for auto-addressing\n",
    "\n",
    "    # Step 1: Create \"array.c\"\n",
    "    array_c_content = ['#include <stdint.h>']\n",
    "    section_names = []\n",
    "\n",
    "    for idx, (array, start_addr) in enumerate(zip(np_arrays, start_addresses)):\n",
    "        # Determine C type from NumPy dtype\n",
    "        c_type = NP_DTYPE_TO_C.get(array.dtype, None)\n",
    "        if c_type is None:\n",
    "            raise TypeError(f\"Unsupported NumPy dtype: {array.dtype}\")\n",
    "\n",
    "        section_name = f\".custom_section_{idx}\"\n",
    "        section_names.append(section_name)\n",
    "        \n",
    "        if start_addr is None:\n",
    "            # Auto-determine the address with alignment\n",
    "            start_addr = (current_address + alignment - 1) & ~(alignment - 1)\n",
    "        else:\n",
    "            # Ensure provided addresses are aligned\n",
    "            if start_addr % alignment != 0:\n",
    "                raise ValueError(f\"Provided address {start_addr} is not {alignment}-byte aligned.\")\n",
    "\n",
    "        # Generate the array definition\n",
    "        array_values = \", \".join(map(str, array.flatten()))\n",
    "        array_c_content.append(\n",
    "            f'{c_type} array_{idx}[] __attribute__((section(\"{section_name}\"))) = {{{array_values}}};'\n",
    "        )\n",
    "\n",
    "        current_address = start_addr + array.nbytes\n",
    "\n",
    "    array_c_code = \"\\n\".join(array_c_content)\n",
    "\n",
    "    with open(\"array.c\", \"w\") as f:\n",
    "        f.write(array_c_code)\n",
    "\n",
    "\n",
    "    # Step 2: Create \"link.ld\"\n",
    "    link_ld_content = [\"SECTIONS {\"]\n",
    "    current_address = 0xc0000000  # Reset for linker script auto-addressing\n",
    "\n",
    "    for idx, (array, start_addr) in enumerate(zip(np_arrays, start_addresses)):\n",
    "        section_name = section_names[idx]\n",
    "\n",
    "        if start_addr is None:\n",
    "            # Auto-determine the address with alignment\n",
    "            start_addr = (current_address + alignment - 1) & ~(alignment - 1)\n",
    "        link_ld_content.append(\n",
    "            f\"    . = 0x{start_addr:X};\\n    {section_name} : {{ *({section_name}) }}\"\n",
    "        )\n",
    "        current_address = start_addr + array.nbytes\n",
    "\n",
    "    link_ld_content.append(\"}\")\n",
    "    link_ld_code = \"\\n\".join(link_ld_content)\n",
    "\n",
    "    with open(\"link.ld\", \"w\") as f:\n",
    "        f.write(link_ld_code)\n",
    "\n",
    "    # Step 3: Compile the ELF file\n",
    "    os.system(\"riscv32-unknown-elf-gcc -c array.c -o array.o\")\n",
    "    os.system(f\"riscv32-unknown-elf-ld -T link.ld array.o -o {output_file_path}\")\n",
    "    os.system(f\"riscv32-unknown-elf-strip --remove-section=.comment --remove-section=.Pulp_Chip.Info {output_file_path}\")\n",
    "\n",
    "    # Step 4: Cleanup\n",
    "    os.remove(\"array.c\")\n",
    "    os.remove(\"link.ld\")\n",
    "    os.remove(\"array.o\")\n",
    "\n",
    "\n",
    "def make_preload_elf_hbm_interleaved(output_file_path, np_arrays, split_schemes, placement_schemes, hardware_block_sizes, start_addresses=None):\n",
    "    \"\"\"\n",
    "    Split np arrays into tiles and blocks and then use make_preload_elf to generate an ELF file preloading numpy arrays.\n",
    "\n",
    "    \"\"\"\n",
    "    # Split the numpy arrays\n",
    "    args = []    \n",
    "    split_arrays = []\n",
    "    split_arrays.append(args)\n",
    "    split_arrays_start_addresses = []\n",
    "    split_arrays_start_addresses.append(0xc0000000) # for store args\n",
    "    current_start_address = 64\n",
    "    for array, split_scheme, placement_scheme, hardware_block_size in zip(np_arrays, split_schemes, placement_schemes, hardware_block_sizes):\n",
    "        args.append(current_start_address)\n",
    "        # print(f\"hardware_block_size: {hardware_block_size[0]}x{hardware_block_size[1]}\")\n",
    "        block_height = hardware_block_size[0]\n",
    "        block_length = hardware_block_size[1]\n",
    "        block_size = block_height * block_length * np.dtype(array.dtype).itemsize\n",
    "        # print(f\"block_size: {block_size}\")\n",
    "        channel_start = placement_scheme[0]\n",
    "        # print(f\"channel_start: {channel_start}\")\n",
    "        channel_end = placement_scheme[1]\n",
    "        # print(f\"channel_end: {channel_end}\")\n",
    "        channel_stride = placement_scheme[2]\n",
    "        # print(f\"channel_stride: {channel_stride}\")\n",
    "        num_channels = (channel_end - channel_start + 1) // channel_stride\n",
    "        array_shape = array.shape\n",
    "        # print(f\"array_shape: {array_shape}\")\n",
    "        tile_height = array_shape[0] // split_scheme[0]\n",
    "        # print(f\"tile_height: {tile_height}\")\n",
    "        tile_length = array_shape[1] // split_scheme[1]\n",
    "        # print(f\"tile_length: {tile_length}\")\n",
    "        tile_size = tile_length * tile_height * np.dtype(array.dtype).itemsize\n",
    "        # print(f\"tile_size: {tile_size}\")\n",
    "        for i in range(split_scheme[0]):\n",
    "            for j in range(split_scheme[1]):\n",
    "                tile_idx = i * split_scheme[1] + j\n",
    "                # print(f\"tile_idx: {tile_idx}\")\n",
    "                channel_offset = tile_idx % num_channels\n",
    "                # print(f\"channel_offset: {channel_offset}\")\n",
    "                channel_idx = channel_start + channel_offset * channel_stride\n",
    "                # print(f\"channel_idx: {channel_idx}\")\n",
    "                tile = array[i*tile_height:(i+1)*tile_height, j*tile_length:(j+1)*tile_length]\n",
    "                for bi in range(0, tile_height, block_height):\n",
    "                    for bj in range(0, tile_length, block_length):\n",
    "                        # print(f\"bi: {bi}, bj: {bj}\")\n",
    "                        block = tile[bi:bi+block_height, bj:bj+block_length] \n",
    "                        split_arrays.append(block)\n",
    "                        bi_index = bi // block_height\n",
    "                        bj_index = bj // block_length\n",
    "                        \n",
    "                        block_address = 0xc0000000 + current_start_address + channel_idx * 0x08000000 + (tile_idx // num_channels) * tile_size + (bi_index * tile_length // block_length + bj_index) * block_size\n",
    "                        # print(f\"block_address: {hex(block_address)}\")\n",
    "                        split_arrays_start_addresses.append(block_address)\n",
    "        current_start_address += array.nbytes // num_channels\n",
    "\n",
    "\n",
    "    args.append(K)\n",
    "    args.append(M)\n",
    "    args.append(N)\n",
    "    # args to np arrays\n",
    "    args = np.array(args, dtype=np.uint32)  \n",
    "\n",
    "    # replace the args in split_arrays with new args\n",
    "    split_arrays[0] = args\n",
    "\n",
    "    make_preload_elf(output_file_path, split_arrays, split_arrays_start_addresses)\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "M = dace.symbol(\"M\")\n",
    "N = dace.symbol(\"N\")\n",
    "K = dace.symbol(\"K\")\n",
    "split_scheme_A = (4, 8)\n",
    "split_scheme_B = (2, 2)\n",
    "split_scheme_C = (2, 2)\n",
    "placement_scheme_A = (0, 3, 1)\n",
    "placement_scheme_B = (0, 3, 1)\n",
    "placement_scheme_C = (0, 3, 1)\n",
    "\n",
    "def _my_gen_matmul_sdfg(hardware_matmul_mnk: typing.Tuple,\n",
    "                     global_storage: dace.dtypes.StorageType,\n",
    "                     local_storage: dace.dtypes.StorageType,\n",
    "                     device_schedule: dace.dtypes.ScheduleType,\n",
    "                     thread_group_schedule: dace.dtypes.ScheduleType,\n",
    "                     thread_group_dims: typing.Tuple,\n",
    "                     hbm_split_scheme: typing.List[typing.Tuple[int, int]],\n",
    "                     hbm_placement_scheme: typing.List[typing.Tuple[int, int]],\n",
    "                     input_float,\n",
    "                     output_float,\n",
    "                     coarsening_factor,\n",
    "                     mmad_tasklet_str: str,\n",
    "                     is_hbm_interleaved: bool = False):\n",
    "    sdfg = dace.SDFG(\"GEMM\")\n",
    "    tM, tN, tK = hardware_matmul_mnk\n",
    "    tM *= coarsening_factor\n",
    "    tN *= coarsening_factor\n",
    "    tK *= coarsening_factor\n",
    "    gM, gN = thread_group_dims\n",
    "\n",
    "    main_state = sdfg.add_state(\"main\")\n",
    "    state = main_state\n",
    "\n",
    "    arrs = dict()\n",
    "    for arr_name, shape, ftype in [(\"A\", (M, K), input_float), (\"B\", (K, N), input_float), (\"C\", (M, N), output_float)]:\n",
    "        if arr_name == \"A\":\n",
    "            arrn, arr = sdfg.add_array(name=arr_name, shape=shape, dtype=ftype, storage=global_storage, transient=False, is_hbm_interleaved=is_hbm_interleaved, hbm_split_scheme=hbm_split_scheme[0], hbm_placement_scheme=hbm_placement_scheme[0])\n",
    "            arrs[arrn] = arr\n",
    "        if arr_name == \"B\":\n",
    "            arrn, arr = sdfg.add_array(name=arr_name, shape=shape, dtype=ftype, storage=global_storage, transient=False, is_hbm_interleaved=is_hbm_interleaved, hbm_split_scheme=hbm_split_scheme[1], hbm_placement_scheme=hbm_placement_scheme[1])\n",
    "            arrs[arrn] = arr\n",
    "        if arr_name == \"C\":\n",
    "            arrn, arr = sdfg.add_array(name=arr_name, shape=shape, dtype=ftype, storage=global_storage, transient=False, is_hbm_interleaved=is_hbm_interleaved, hbm_split_scheme=hbm_split_scheme[2], hbm_placement_scheme=hbm_placement_scheme[2])\n",
    "            arrs[arrn] = arr\n",
    "    arrn, arr = sdfg.add_array(name=\"accumulator\", shape=(coarsening_factor*coarsening_factor, tM//coarsening_factor, tN//coarsening_factor), dtype=ftype, storage=local_storage, transient=True)\n",
    "    arrs[arrn] = arr\n",
    "\n",
    "    dev_map_entry, dev_map_exit = main_state.add_map(\n",
    "        name=\"gemm_entry\",\n",
    "        ndrange={\"i\" : dace.subsets.Range([(0, M-1, tM*gM)]),\n",
    "                 \"j\" : dace.subsets.Range([(0, N-1, tN*gN)])},\n",
    "        schedule=device_schedule\n",
    "    )\n",
    "    for name in [\"A\", \"B\", \"C\"]:\n",
    "    # for name in [\"A\", \"B\"]:\n",
    "        if name == \"A\" or name == \"B\":\n",
    "            access_str = \", \".join([f\"0:{n}\" for n in arrs[name].shape])\n",
    "            an = state.add_access(name)\n",
    "            state.add_edge(an, None, dev_map_entry, f\"IN_{name}\", dace.memlet.Memlet(f\"{name}[{access_str}]\"))\n",
    "            dev_map_entry.add_in_connector(f\"IN_{name}\")\n",
    "        if name == \"C\":\n",
    "            access_str = \", \".join([f\"0:{n}\" for n in arrs[name].shape])\n",
    "            # an = state.add_access(name)\n",
    "            dev_map_exit.add_out_connector(f\"OUT_{name}\")\n",
    "            anc3 = state.add_access(name)\n",
    "            state.add_edge(dev_map_exit, f\"OUT_{name}\", anc3, None, dace.memlet.Memlet(f\"{name}[{access_str}]\"))\n",
    "\n",
    "    thread_group_map_entry, thread_group_map_exit = main_state.add_map(\n",
    "        name=\"thread_group_mmad\",\n",
    "        ndrange={\"gi\" : dace.subsets.Range([(0, gM-1, 1)]),\n",
    "                 \"gj\" : dace.subsets.Range([(0, gM-1, 1)])},\n",
    "        schedule=thread_group_schedule\n",
    "    )\n",
    "\n",
    "    for name in [\"A\", \"B\", \"C\"]:\n",
    "        if name == \"A\" or name == \"B\":\n",
    "            if name == \"A\":\n",
    "                access_str = \", \".join([f\"i:i + {tM} * {gM}\", \"0:K\"])\n",
    "            elif name == \"B\":\n",
    "                access_str = \", \".join([\"0:K\", f\"j:j + {tN} * {gN}\"])\n",
    "            elif name == \"C\":\n",
    "                access_str = \", \".join([f\"i:i + {gM} * {tM}\", f\"j:j + {gN} * {tN}\"])\n",
    "            state.add_edge(dev_map_entry, f\"OUT_{name}\", thread_group_map_entry, f\"IN_{name}\", dace.memlet.Memlet(f\"{name}[{access_str}]\"))\n",
    "            dev_map_entry.add_out_connector(f\"OUT_{name}\")\n",
    "            thread_group_map_entry.add_in_connector(f\"IN_{name}\")\n",
    "        if name == \"C\":\n",
    "            access_str = \", \".join([f\"i:i + {gM} * {tM}\", f\"j:j + {gN} * {tN}\"])\n",
    "            state.add_edge(thread_group_map_exit, f\"OUT_{name}\", dev_map_exit, f\"IN_{name}\", dace.memlet.Memlet(f\"{name}[{access_str}]\"))\n",
    "            dev_map_exit.add_in_connector(f\"IN_{name}\")\n",
    "            thread_group_map_exit.add_out_connector(f\"OUT_{name}\")\n",
    "\n",
    "    thread_coarsened_map_entry, thread_coarsened_map_exit = main_state.add_map(\n",
    "        name=\"thread_coarsened\",\n",
    "        ndrange={\"ci\" : dace.subsets.Range([(0, tM-1, tM//coarsening_factor)]),\n",
    "                 \"cj\" : dace.subsets.Range([(0, tN-1, tN//coarsening_factor)])},\n",
    "        schedule=dace.dtypes.ScheduleType.SoftHier_Sequential\n",
    "    )\n",
    "\n",
    "    for name in [\"A\", \"B\", \"C\"]:\n",
    "        if name == \"A\" or name == \"B\":\n",
    "                if name == \"A\":\n",
    "                    access_str = \", \".join([f\"i + gi * {tM}:i + gi * {tM} + {tM}\", \"0:K\"])\n",
    "                elif name == \"B\":\n",
    "                    access_str = \", \".join([\"0:K\", f\"j + gj * {tN}:j + gj * {tN} + {tN}\"])\n",
    "                elif name == \"C\":\n",
    "                    access_str = \", \".join([f\"i + gj * {tM}:i + gj * {tM} + {tM}\", f\"j + gj * {tN}:j + gj * {tN} + {tN}\"])\n",
    "                state.add_edge(thread_group_map_entry, f\"OUT_{name}\", thread_coarsened_map_entry, f\"IN_{name}\", dace.memlet.Memlet(f\"{name}[{access_str}]\"))\n",
    "                thread_group_map_entry.add_out_connector(f\"OUT_{name}\")\n",
    "                thread_coarsened_map_entry.add_in_connector(f\"IN_{name}\")\n",
    "        if name == \"C\":\n",
    "            access_str = \", \".join([f\"i + gj * {tM}:i + gj * {tM} + {tM}\", f\"j + gj * {tN}:j + gj * {tN} + {tN}\"])\n",
    "            state.add_edge(thread_coarsened_map_exit, f\"OUT_{name}\", thread_group_map_exit, f\"IN_{name}\", dace.memlet.Memlet(f\"{name}[{access_str}]\"))\n",
    "            thread_group_map_exit.add_in_connector(f\"IN_{name}\")\n",
    "            thread_coarsened_map_exit.add_out_connector(f\"OUT_{name}\")\n",
    "\n",
    "    block_tiled_map_entry, block_tiled_map_exit = main_state.add_map(\n",
    "        name=\"block_tiled\",\n",
    "        ndrange={\"bK\" : dace.subsets.Range([(0, K-1, tK//coarsening_factor)])},\n",
    "        schedule=dace.dtypes.ScheduleType.SoftHier_Sequential\n",
    "    )\n",
    "\n",
    "    accumulator_an = state.add_access(\"accumulator\")\n",
    "    accumulator_an.setzero = True\n",
    "    state.add_edge(thread_coarsened_map_entry, None, accumulator_an, None, dace.memlet.Memlet(None))\n",
    "    access_str = \", \".join([f\"0:{coarsening_factor}*{coarsening_factor}\", f\"0:{tM//coarsening_factor}\", f\"0:{tN//coarsening_factor}\"])\n",
    "    state.add_edge(accumulator_an, None, block_tiled_map_entry, f\"IN_accumulator\", dace.memlet.Memlet(f\"accumulator[{access_str}]\"))\n",
    "    block_tiled_map_entry.add_in_connector(\"IN_accumulator\")\n",
    "    thread_group_map_entry\n",
    "\n",
    "\n",
    "    for name in [\"A\", \"B\"]:\n",
    "        if name == \"A\":\n",
    "            access_str = \", \".join([f\"i + gi * {tM} + ci * {tM//coarsening_factor}:i + gi * {tM} + ci * {tM//coarsening_factor} + {tM//coarsening_factor}\", \"0:K\"])\n",
    "        elif name == \"B\":\n",
    "            access_str = \", \".join([\"0:K\", f\"j + gj * {tN} + cj * {tN//coarsening_factor}:j + gj * {tN} + cj * {tN//coarsening_factor} + {tN//coarsening_factor}\"])\n",
    "\n",
    "        state.add_edge(thread_coarsened_map_entry, f\"OUT_{name}\", block_tiled_map_entry, f\"IN_{name}\", dace.memlet.Memlet(f\"{name}[{access_str}]\"))\n",
    "        block_tiled_map_entry.add_in_connector(f\"IN_{name}\")\n",
    "        thread_coarsened_map_entry.add_out_connector(f\"OUT_{name}\")\n",
    "\n",
    "\n",
    "    # Load\n",
    "    local_access_nodes = dict()\n",
    "    for name, shape in [(\"A\", (tM//coarsening_factor, tK//coarsening_factor)), (\"B\", (tK//coarsening_factor, tN//coarsening_factor))]:\n",
    "        block_tiled_map_entry.add_out_connector(f\"OUT_{name}\")\n",
    "        arrn, arr = sdfg.add_array(name=f\"local_{name}\", shape=shape, dtype=input_float, storage=local_storage, transient=True)\n",
    "        arrs[arrn] = arr\n",
    "        an = state.add_access(f\"local_{name}\")\n",
    "        local_access_nodes[f\"local_{name}\"] = an\n",
    "        if name == \"A\":\n",
    "            access_str = \", \".join([f\"i + gi * {tM} + ci * {tM//coarsening_factor}:i + gi * {tM} + ci * {tM//coarsening_factor} + {tM//coarsening_factor}\", \n",
    "                                    f\"bK:bK+{tK//coarsening_factor}\"])\n",
    "        elif name == \"B\":\n",
    "            access_str = \", \".join([f\"bK:bK+{tK//coarsening_factor}\", \n",
    "                                    f\"j + gj * {tN} + cj * {tN//coarsening_factor}:j + gj * {tN} + cj * {tN//coarsening_factor} + {tN//coarsening_factor}\"])\n",
    "        state.add_edge(block_tiled_map_entry, f\"OUT_{name}\", an, None, dace.memlet.Memlet(f\"{name}[{access_str}]\"))\n",
    "\n",
    "    # Connect local_A + local_B -> matmul -> accumulator\n",
    "    matmul_tasklet = state.add_tasklet(name=\"mmad_redmule\", inputs={\"_in_local_a\", \"_in_local_b\", \"_in_accumulator\"}, outputs={\"_out_accumulator\"},\n",
    "                                       code=mmad_tasklet_str, language=dace.dtypes.Language.CPP)\n",
    "\n",
    "    #for name in [\"local_A\", \"local_B\", \"accumulate\"]:\n",
    "    #    state.add_edge()\n",
    "\n",
    "    for name, an in local_access_nodes.items():\n",
    "        state.add_edge(an, None, matmul_tasklet, \"_in_\" + name.lower(), dace.memlet.Memlet(name))\n",
    "    state.add_edge(block_tiled_map_entry, f\"OUT_accumulator\", matmul_tasklet, \"_in_accumulator\", dace.memlet.Memlet(\"accumulator\"))\n",
    "    # accumulator_an2 = state.add_access(\"accumulator\")\n",
    "    # state.add_edge(matmul_tasklet, f\"_out_accumulator\", accumulator_an2, None, dace.memlet.Memlet(\"accumulator\"))\n",
    "    # state.add_edge(accumulator_an2, None, block_tiled_map_exit, \"IN_accumulator\", dace.memlet.Memlet(\"accumulator\"))\n",
    "    access_str = \", \".join([f\"0:{coarsening_factor}*{coarsening_factor}\", f\"0:{tM//coarsening_factor}\", f\"0:{tN//coarsening_factor}\"])\n",
    "    state.add_edge(matmul_tasklet, \"_out_accumulator\", block_tiled_map_exit, \"IN_accumulator\", dace.memlet.Memlet(f\"accumulator[{access_str}]\"))\n",
    "    block_tiled_map_entry.add_in_connector(\"IN_accumulator\")\n",
    "    block_tiled_map_exit.add_in_connector(\"IN_accumulator\")\n",
    "    block_tiled_map_entry.add_out_connector(\"OUT_accumulator\")\n",
    "    block_tiled_map_exit.add_out_connector(\"OUT_accumulator\")\n",
    "\n",
    "\n",
    "    # assign_tasklet = state.add_tasklet(name=\"assign\", inputs={\"_in_accumulator\"}, outputs={\"_out_C\"}, code=\"_out_C = _in_accumulator\")\n",
    "    # state.add_edge(block_tiled_map_exit, \"OUT_C\", assign_tasklet, \"_in_accumulator\", dace.memlet.Memlet(\"accumulator\")) , \"_in_C\"\n",
    "\n",
    "    # accumulator_an3 = state.add_access(\"accumulator\")\n",
    "    # state.add_edge(block_tiled_map_exit, f\"OUT_accumulator\", accumulator_an3, None, dace.memlet.Memlet(\"accumulator\"))\n",
    "    # state.add_edge(accumulator_an3, None, assign_tasklet, \"_in_accumulator\", dace.memlet.Memlet(\"accumulator\"))\n",
    "    # state.add_edge(block_tiled_map_exit, f\"OUT_accumulator\", assign_tasklet, \"_in_accumulator\", dace.memlet.Memlet())\n",
    "\n",
    "    # c_an2 = state.add_access(\"C\")\n",
    "    accumulator_an3 = state.add_access(\"accumulator\")\n",
    "    \n",
    "    # state.add_edge(assign_tasklet, \"_out_C\", c_an2, None, dace.memlet.Memlet(f\"C[{access_str}]\"))\n",
    "    # thread_coarsened_map_entry.add_out_connector(f\"OUT_C\")\n",
    "    # state.add_edge(c_an2, None, thread_coarsened_map_exit, \"IN_C\", dace.memlet.Memlet(f\"C[{access_str}]\"))\n",
    "    # state.add_edge(assign_tasklet, \"_out_C\", thread_coarsened_map_exit, \"IN_C\", dace.memlet.Memlet(f\"C[{access_str}]\"))\n",
    "    # state.add_edge(block_tiled_map_exit, f\"OUT_accumulator\", thread_coarsened_map_exit, \"IN_C\", dace.memlet.Memlet(f\"C[{access_str}]\"))\n",
    "    access_str = \", \".join([f\"0:{coarsening_factor}*{coarsening_factor}\", f\"0:{tM//coarsening_factor}\", f\"0:{tN//coarsening_factor}\"])\n",
    "    state.add_edge(block_tiled_map_exit, f\"OUT_accumulator\", accumulator_an3, None, dace.memlet.Memlet(f\"accumulator[{access_str}]\"))\n",
    "    access_str = \", \".join([f\"i + gi * {tM} + ci * {tM//coarsening_factor}:i + gi * {tM} + ci * {tM//coarsening_factor} + {tM//coarsening_factor}\", \n",
    "                            f\"j + gj * {tN} + cj * {tN//coarsening_factor}:j + gj * {tN} + cj * {tN//coarsening_factor} + {tN//coarsening_factor}\"])\n",
    "    state.add_edge(accumulator_an3, None, thread_coarsened_map_exit, \"IN_C\", dace.memlet.Memlet(f\"C[{access_str}]\"))\n",
    "    thread_coarsened_map_exit.add_in_connector(\"IN_C\")\n",
    "\n",
    "    # DoubleBuffering.apply_to(sdfg, map_entry=block_tiled_map_entry, transient=local_access_nodes[\"local_A\"])\n",
    "    return sdfg\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    sdfg = _my_gen_matmul_sdfg(hardware_matmul_mnk=(64, 16, 32),\n",
    "                            global_storage=dace.dtypes.StorageType.SoftHier_HBM,\n",
    "                            local_storage=dace.dtypes.StorageType.SoftHier_TCDM,\n",
    "                            device_schedule=dace.dtypes.ScheduleType.SoftHier_Device,\n",
    "                            thread_group_schedule=dace.dtypes.ScheduleType.SoftHier_Cluster,\n",
    "                            thread_group_dims=(4, 4),\n",
    "                            hbm_split_scheme=[split_scheme_A, split_scheme_B, split_scheme_C],\n",
    "                            hbm_placement_scheme=[placement_scheme_A, placement_scheme_B, placement_scheme_C],\n",
    "                            is_hbm_interleaved=True,\n",
    "                            input_float=dace.float16,\n",
    "                            output_float=dace.float16,\n",
    "                            coarsening_factor=1,\n",
    "                            mmad_tasklet_str=\"flex_redmule_trigger(_in_local_a, _in_local_b, _in_accumulator, REDMULE_FP_16);\")\n",
    "    sdfg.save(\"my_gemm.sdfgz\")\n",
    "    sdfg.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import Code\n",
    "# Code(sdfg.generate_code()[1].clean_code, language='cpp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sdfg.compile()\n",
    "# import numpy as np\n",
    "K = 512\n",
    "M = 512\n",
    "N = 512\n",
    "# A_host = np.random.rand(M, K).astype(np.float16)\n",
    "# B_host = np.random.rand(K, N).astype(np.float16)\n",
    "A_host = np.ones((M, K), dtype=np.float16)\n",
    "B_host = np.ones((K, N), dtype=np.float16)\n",
    "C_host = np.zeros((M, N), dtype=np.float16)\n",
    "\n",
    "for i in range(M):\n",
    "    for j in range(K):\n",
    "        if np.random.rand() < 0.5:\n",
    "            A_host[i, j] += 1\n",
    "for i in range(K):\n",
    "    for j in range(N):\n",
    "        if np.random.rand() < 0.5:\n",
    "            B_host[i, j] = 1\n",
    "\n",
    "for i in range(M):\n",
    "    for j in range(K):\n",
    "        if np.random.rand() < 0.1:\n",
    "            A_host[i, j] += 4\n",
    "for i in range(K):\n",
    "    for j in range(N):\n",
    "        if np.random.rand() < 0.1:\n",
    "            B_host[i, j] += 4\n",
    "\n",
    "args = make_preload_elf_hbm_interleaved(\"/usr/scratch/badile111/dace4softhier/gvsoc/output.elf\", [A_host, B_host, C_host], [split_scheme_A, split_scheme_B, split_scheme_C], [placement_scheme_A, placement_scheme_B, placement_scheme_C], [(64, 32), (32, 16), (64, 16)], start_addresses=[])\n",
    "\n",
    "\n",
    "# make_preload_elf(\"/usr/scratch/badile111/dace4softhier/gvsoc/output.elf\", [args, A_host, B_host, C_host])\n",
    "# print(A_host@B_host)\n",
    "sdfg(A=A_host, B=B_host, C=C_host, M=M, N=N, K=K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = A_host@B_host\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(A_host)\n",
    "print(B_host)\n",
    "\n",
    "print(A_host[0,64])\n",
    "print(A_host[0,65])\n",
    "\n",
    "print(B_host[0,256])\n",
    "print(B_host[0,257])\n",
    "print(result[0][0])\n",
    "print(result[0][1])\n",
    "\n",
    "print(result[256][256])\n",
    "\n",
    "\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
